<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Validate an existing prediction — pred_validate • predRupdate</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Validate an existing prediction — pred_validate"><meta name="description" content="Validate an existing prediction model, to calculate the predictive
performance against a new (validation) dataset."><meta property="og:description" content="Validate an existing prediction model, to calculate the predictive
performance against a new (validation) dataset."><meta property="og:image" content="https://glenmartin31.github.io/predRupdate/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">predRupdate</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/predRupdate.html">Get started</a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/predRupdate_splineIllustration.html">Example of Validating a Model that Includes Spline Terms</a></li>
    <li><a class="dropdown-item" href="../articles/predRupdate_technical.html">Technical Background to predRupdate</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/GlenMartin31/predRupdate/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Validate an existing prediction</h1>
      <small class="dont-index">Source: <a href="https://github.com/GlenMartin31/predRupdate/blob/master/R/pred_validate.R" class="external-link"><code>R/pred_validate.R</code></a></small>
      <div class="d-none name"><code>pred_validate.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Validate an existing prediction model, to calculate the predictive
performance against a new (validation) dataset.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">pred_validate</span><span class="op">(</span></span>
<span>  <span class="va">x</span>,</span>
<span>  <span class="va">new_data</span>,</span>
<span>  binary_outcome <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  survival_time <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  event_indicator <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  time_horizon <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  level <span class="op">=</span> <span class="fl">0.95</span>,</span>
<span>  cal_plot <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-x">x<a class="anchor" aria-label="anchor" href="#arg-x"></a></dt>
<dd><p>an object of class "<code>predinfo</code>" produced by calling
<code><a href="pred_input_info.html">pred_input_info</a></code>.</p></dd>


<dt id="arg-new-data">new_data<a class="anchor" aria-label="anchor" href="#arg-new-data"></a></dt>
<dd><p>data.frame upon which the prediction model should be
evaluated.</p></dd>


<dt id="arg-binary-outcome">binary_outcome<a class="anchor" aria-label="anchor" href="#arg-binary-outcome"></a></dt>
<dd><p>Character variable giving the name of the column in
<code>new_data</code> that represents the observed binary outcomes (should be
coded 0 and 1 for non-event and event, respectively). Only relevant for
<code>model_type</code>="logistic"; leave as <code>NULL</code> otherwise. Leave as
<code>NULL</code> if <code>new_data</code> does not contain any outcomes.</p></dd>


<dt id="arg-survival-time">survival_time<a class="anchor" aria-label="anchor" href="#arg-survival-time"></a></dt>
<dd><p>Character variable giving the name of the column in
<code>new_data</code> that represents the observed survival times. Only relevant
for <code>x$model_type</code>="survival"; leave as <code>NULL</code> otherwise.</p></dd>


<dt id="arg-event-indicator">event_indicator<a class="anchor" aria-label="anchor" href="#arg-event-indicator"></a></dt>
<dd><p>Character variable giving the name of the column in
<code>new_data</code> that represents the observed survival indicator (1 for
event, 0 for censoring). Only relevant for <code>x$model_type</code>="survival";
leave as <code>NULL</code> otherwise.</p></dd>


<dt id="arg-time-horizon">time_horizon<a class="anchor" aria-label="anchor" href="#arg-time-horizon"></a></dt>
<dd><p>for survival models, an integer giving the time horizon
(post baseline) at which a prediction is required. Currently, this must
match a time in x$cum_hazard.</p></dd>


<dt id="arg-level">level<a class="anchor" aria-label="anchor" href="#arg-level"></a></dt>
<dd><p>the confidence level required for all performance metrics.
Defaults at 95%. Must be a value between 0 and 1.</p></dd>


<dt id="arg-cal-plot">cal_plot<a class="anchor" aria-label="anchor" href="#arg-cal-plot"></a></dt>
<dd><p>indicate if a flexible calibration plot should be produced
(TRUE) or not (FALSE).</p></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>further plotting arguments for the calibration plot. See Details
below.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p><code>pred_validate</code> returns an object of class
"<code>predvalidate</code>", with child classes per <code>model_type</code>. This is a
list of performance metrics, estimated by applying the existing prediction
model to the new_data. An object of class "<code>predvalidate</code>" is a list
containing relevant calibration and discrimination measures. For logistic
regression models, this will include observed:expected ratio,
calibration-intercept, calibration slope, area under the ROC curve,
R-squared, and Brier Score. For survival models, this will include
observed:expected ratio (if <code>cum_hazard</code> is provided to <code>x</code>),
calibration slope, and Harrell's C-statistic. Optionally, a flexible
calibration plot is also produced, along with a box-plot and violin plot of
the predicted risk distribution.</p>
<p>The <code>summary</code> function can be used to extract and print summary
performance results (calibration and discrimination metrics). The graphical
assessments of performance can be extracted using <code>plot</code>.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>This function takes an existing prediction model formatted according
to <code><a href="pred_input_info.html">pred_input_info</a></code>, and calculates measures of predictive
performance on new data (e.g., within an external validation study). The
information about the existing prediction model should first be inputted by
calling <code><a href="pred_input_info.html">pred_input_info</a></code>, before passing the resulting object
to <code>pred_validate</code>.</p>
<p><code>new_data</code> should be a data.frame, where each row should be an
observation (e.g. patient) and each variable/column should be a predictor
variable. The predictor variables need to include (as a minimum) all of the
predictor variables that are included in the existing prediction model
(i.e., each of the variable names supplied to
<code><a href="pred_input_info.html">pred_input_info</a></code>, through the <code>model_info</code> parameter,
must match the name of a variables in <code>new_data</code>).</p>
<p>Any factor variables within <code>new_data</code> must be converted to dummy
(0/1) variables before calling this function. <code><a href="dummy_vars.html">dummy_vars</a></code> can
help with this. See <code><a href="pred_predict.html">pred_predict</a></code> for examples.</p>
<p><code>binary_outcome</code>, <code>survival_time</code> and <code>event_indicator</code> are
used to specify the outcome variable(s) within <code>new_data</code> (use
<code>binary_outcome</code> if <code>x$model_type</code> = "logistic", or use
<code>survival_time</code> and <code>event_indicator</code> if <code>x$model_type</code> =
"survival").</p>
<p>In the case of validating a logistic regression model, this function
assesses the predictive performance of the predicted risks against an
observed binary outcome. Various metrics of calibration (agreement between
the observed risk and the predicted risks, across the full risk range) and
discrimination (ability of the model to distinguish between those who
develop the outcome and those who do not) are calculated. For calibration,
the observed-to-expected ratio, calibration intercept and calibration
slopes are estimated. The calibration intercept is estimated by fitting a
logistic regression model to the observed binary outcomes, with the linear
predictor of the model as an offset. For calibration slope, a logistic
regression model is fit to the observed binary outcome with the linear
predictor from the model as the only covariate. For discrimination, the
function estimates the area under the receiver operating characteristic
curve (AUC). Various other metrics are also calculated to assess overall
accuracy (Brier score, Cox-Snell R2).</p>
<p>In the case of validating a survival prediction model, this function
assesses the predictive performance of the linear predictor and
(optionally) the predicted event probabilities at a fixed time horizon
against an observed time-to-event outcome. Various metrics of calibration
and discrimination are calculated. For calibration, the
observed-to-expected ratio at the specified <code>time_horizon</code> (if
predicted risks are available through specification of <code>x$cum_hazard</code>)
and calibration slope are produced. For discrimination, Harrell's
C-statistic is calculated.</p>
<p>For both model types, a flexible calibration plot is produced (for survival
models, the cumulative baseline hazard must be available in the
<code>predinfo</code> object, <code>x$cum_hazard</code>). Specify parameter
<code>cal_plot</code> to indicate whether a calibration plot should be produced
(TRUE), or not (FALSE). The calibration plot is produced by regressing the
observed outcomes against a cubic spline of the logit of predicted risks
(for a logistic model) or the complementary log-log of the predicted risks
(for a survival model). Users can specify the following additional
parameters to <code>pred_validate</code> to modify the calibration plot:</p><ul><li><p><code>xlim</code> as a numeric vector of length 2, giving the lower and
upper range of the x-axis scale - defaults at 0 and 1. Changes here should
match changes to the <code>ylim</code> such that the plot remains 'square'.</p></li>
<li><p><code>ylim</code> as a numeric vector of length 2, giving the lower and
upper range of the y-axis scale - defaults at 0 and 1. Changes here should
match changes to the <code>xlim</code> such that the plot remains 'square'.</p></li>
<li><p><code>xlab</code> string giving the x-axis label. Defaults as
"Predicted Probability".</p></li>
<li><p><code>ylab</code> string giving the x-axis label. Defaults as
"Observed Probability".</p></li>
<li><p><code>pred_rug</code> TRUE/FALSE of whether a 'rug' should be placed
along the x-axis of the calibration plot showing the distribution of
predicted risks. Defaults as FALSE in favour of examining the
box-plot/violin plot that is produced.</p></li>
<li><p><code>cal_plot_n_sample</code> numeric value (less than nrow(new_data))
giving a random subset of observations to render the calibration plot
over. The calibration plot is always created using all data, but for
rendering speed in large datasets, it can sometimes be useful to render
the plot over a smaller (random) subset of observations.
Final (e.g. publication-ready) plots should always show the full plot,
so a warning is created if users enter a value of cal_plot_n_sample.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code><a href="pred_input_info.html">pred_input_info</a></code></p></div>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co">#Example 1 - multiple existing model, with outcome specified; uses</span></span></span>
<span class="r-in"><span><span class="co">#            an example dataset within the package</span></span></span>
<span class="r-in"><span><span class="va">model1</span> <span class="op">&lt;-</span> <span class="fu"><a href="pred_input_info.html">pred_input_info</a></span><span class="op">(</span>model_type <span class="op">=</span> <span class="st">"logistic"</span>,</span></span>
<span class="r-in"><span>                          model_info <span class="op">=</span> <span class="va">SYNPM</span><span class="op">$</span><span class="va">Existing_logistic_models</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">val_results</span> <span class="op">&lt;-</span> <span class="fu">pred_validate</span><span class="op">(</span>x <span class="op">=</span> <span class="va">model1</span>,</span></span>
<span class="r-in"><span>                             new_data <span class="op">=</span> <span class="va">SYNPM</span><span class="op">$</span><span class="va">ValidationData</span>,</span></span>
<span class="r-in"><span>                             binary_outcome <span class="op">=</span> <span class="st">"Y"</span>,</span></span>
<span class="r-in"><span>                             cal_plot <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">val_results</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Performance Results for Model 1 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ================================= </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Measures </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> --------------------------------- </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                         Estimate Lower 95% Confidence Interval</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Observed:Expected Ratio   1.9006                        1.8368</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Intercept     0.7323                        0.6921</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Slope         0.6484                        0.5576</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                         Upper 95% Confidence Interval</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Observed:Expected Ratio                        1.9666</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Intercept                          0.7726</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Slope                              0.7392</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Also examine the calibration plot, if produced. </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Discrimination Measures </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> --------------------------------- </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     Estimate Lower 95% Confidence Interval Upper 95% Confidence Interval</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> AUC   0.5814                        0.5702                        0.5927</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Overall Performance Measures </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> --------------------------------- </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Cox-Snell R-squared: -0.0481</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Nagelkerke R-squared: -0.0863</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Brier Score (CI): 0.1249 (0.1219, 0.1279)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Also examine the distribution plot of predicted risks. </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Performance Results for Model 2 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ================================= </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Measures </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> --------------------------------- </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                         Estimate Lower 95% Confidence Interval</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Observed:Expected Ratio   0.8945                        0.8645</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Intercept    -0.1325                       -0.1725</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Slope         0.9868                        0.8489</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                         Upper 95% Confidence Interval</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Observed:Expected Ratio                        0.9256</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Intercept                         -0.0926</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Slope                              1.1247</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Also examine the calibration plot, if produced. </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Discrimination Measures </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> --------------------------------- </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     Estimate Lower 95% Confidence Interval Upper 95% Confidence Interval</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> AUC   0.5828                        0.5716                        0.5941</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Overall Performance Measures </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> --------------------------------- </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Cox-Snell R-squared: 0.0074</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Nagelkerke R-squared: 0.0132</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Brier Score (CI): 0.1206 (0.1172, 0.124)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Also examine the distribution plot of predicted risks. </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Performance Results for Model 3 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ================================= </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Measures </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> --------------------------------- </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                         Estimate Lower 95% Confidence Interval</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Observed:Expected Ratio   1.5945                        1.5410</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Intercept     0.5324                        0.4923</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Slope         0.7212                        0.5981</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                         Upper 95% Confidence Interval</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Observed:Expected Ratio                        1.6499</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Intercept                          0.5724</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calibration Slope                              0.8443</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Also examine the calibration plot, if produced. </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Discrimination Measures </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> --------------------------------- </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     Estimate Lower 95% Confidence Interval Upper 95% Confidence Interval</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> AUC   0.5613                        0.5497                        0.5728</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Overall Performance Measures </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> --------------------------------- </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Cox-Snell R-squared: -0.0249</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Nagelkerke R-squared: -0.0446</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Brier Score (CI): 0.1234 (0.1202, 0.1266)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Also examine the distribution plot of predicted risks. </span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Glen P. Martin, David Jenkins, Matthew Sperrin.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

