[{"path":"https://glenmartin31.github.io/predRupdate/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 predRupdate authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate.html","id":"preamble","dir":"Articles","previous_headings":"","what":"Preamble","title":"Introduction to the predRupdate package","text":"predRupdate package includes set functions aid validation clinical prediction model (CPM) given dataset, apply various model updating aggregation methods. vignette aims overview, examples, common workflows using predRupdate package. technical vignette describing methods underpinning package, please see vignette(\"predRupdate_technical\"). package focused situation existing CPM (multiple CPMs) developed (e.g., model published literature), one wishes apply model new dataset. foresee least three use-cases: (1) one wishes validate existing CPM new data estimate model’s predictive performance, .e., external validation; (2) one wishes apply model updating methods existing CPM ‘tailor’ new dataset; (3) multiple existing CPMs, one wishes apply model aggregation (meta-modelling) methods pool models single model new dataset. therefore give three examples use cases.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Introduction to the predRupdate package","text":"data, called SYNPM, used throughout vignette available within predRupdate package. See “?SYNPM” details data. short, data models included SYNPM synthetic, purposes vignette, imagine one interested predicting someone’s risk mortality surgery. Data available 20000 people, records individuals age, gender, smoking status, diabetes status, Creatinine value time surgery. data includes outcomes “ETime” representing time (months) surgery either death end--follow-(5 months), whichever occurred first. variable “Status” indicates patient died (1) right-censored (0), Y denotes binary variable indicating patient died within 1 month.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate.html","id":"example-1-validating-an-existing-prediction-model-on-new-data","dir":"Articles","previous_headings":"","what":"Example 1: validating an existing prediction model on new data","title":"Introduction to the predRupdate package","text":"first example, take situation CPM previously developed (another dataset) predict risk mortality within 1 month surgery, wish validate model dataset test predictive performance (e.g., external validation study). existing model logistic regression model, following predictor variables coefficients (log-odds ratios): Table coefficients existing logistic regression prediction model first step using predRupdate validate model input model information. start creating data.frame model coefficients, columns predictor variable names. information passed pred_input_info() function input information existing model. See pred_input_info() details. Next wish apply model dataset calculate predicted risks individual, compare predictions observed outcomes calculate predictive performance. can achieved pred_validate() function, follows: produces output various metrics model calibration (e.g., calibration intercept slope), discrimination (e.g., area ROC curve) overall performance (e.g., R-squared). can see model poor calibration (calibration intercept slope significantly different 0 1, respectively), poor discrimination. can also obtain flexible calibration plot,  left-panel shows box-plot violin-plot probability distributions, stratified outcome, right-panel shows flexible calibration plot. package returns plots ggplot2 objects, modification plots can made using ggplot2 statements. example, one can change theme plot :  One may wish update model new dataset - see Example 2 . default, 95% CIs calculated performance metric. can changed specifying level, follows:","code":"# create a data.frame of the model coefficients, with columns being variables coefs_table <- data.frame(\"Intercept\" = -3.995, #the intercept needs to be named exactly as given here                           \"Age\" = 0.012,                           \"SexM\" = 0.267,                            \"Smoking_Status\" = 0.751,                           \"Diabetes\" = 0.523,                           \"Creatinine\" = 0.578)  #pass this into pred_input_info() Existing_Logistic_Model <- pred_input_info(model_type = \"logistic\",                                            model_info = coefs_table) summary(Existing_Logistic_Model) #> Information about 1 existing model(s) of type 'logistic'  #>  #> Model Coefficients  #> =================================  #>   Intercept   Age  SexM Smoking_Status Diabetes Creatinine #> 1    -3.995 0.012 0.267          0.751    0.523      0.578 #>  #> Model Functional Form  #> =================================  #> Age + SexM + Smoking_Status + Diabetes + Creatinine validation_results <- pred_validate(x = Existing_Logistic_Model,                                     new_data = SYNPM$ValidationData,                                     binary_outcome = \"Y\") summary(validation_results) #use summary() to obtain a tidy output summary of the model performance #> Calibration Measures  #> ---------------------------------  #>                         Estimate Lower 95% Confidence Interval #> Observed:Expected Ratio   1.8583                        1.7959 #> Calibration Intercept     0.7076                        0.6673 #> Calibration Slope         0.6496                        0.5588 #>                         Upper 95% Confidence Interval #> Observed:Expected Ratio                        1.9228 #> Calibration Intercept                          0.7479 #> Calibration Slope                              0.7403 #>  #>  Also examine the calibration plot, if produced.  #>  #> Discrimination Measures  #> ---------------------------------  #>     Estimate Lower 95% Confidence Interval Upper 95% Confidence Interval #> AUC   0.5816                        0.5703                        0.5928 #>  #>  #> Overall Performance Measures  #> ---------------------------------  #> Cox-Snell R-squared: -0.0446 #> Nagelkerke R-squared: -0.0801 #> Brier Score (CI): 0.1246 (0.1216, 0.1276) #>  #>  Also examine the distribution plot of predicted risks. plot(validation_results) validation_results$flex_calibrationplot +    ggplot2::theme_classic() +   ggplot2::xlim(c(0,0.5)) + ggplot2:::ylim(c(0,0.5)) #> Scale for x is already present. #> Adding another scale for x, which will replace the existing scale. #> Scale for y is already present. #> Adding another scale for y, which will replace the existing scale. validation_results <- pred_validate(x = Existing_Logistic_Model,                                     new_data = SYNPM$ValidationData,                                     binary_outcome = \"Y\",                                     level = 0.90) summary(validation_results) #use summary() to obtain a tidy output summary of the model performance #> Calibration Measures  #> ---------------------------------  #>                         Estimate Lower 90% Confidence Interval #> Observed:Expected Ratio   1.8583                        1.8058 #> Calibration Intercept     0.7076                        0.6738 #> Calibration Slope         0.6496                        0.5734 #>                         Upper 90% Confidence Interval #> Observed:Expected Ratio                        1.9123 #> Calibration Intercept                          0.7414 #> Calibration Slope                              0.7257 #>  #>  Also examine the calibration plot, if produced.  #>  #> Discrimination Measures  #> ---------------------------------  #>     Estimate Lower 90% Confidence Interval Upper 90% Confidence Interval #> AUC   0.5816                        0.5722                         0.591 #>  #>  #> Overall Performance Measures  #> ---------------------------------  #> Cox-Snell R-squared: -0.0446 #> Nagelkerke R-squared: -0.0801 #> Brier Score (CI): 0.1246 (0.1221, 0.1272) #>  #>  Also examine the distribution plot of predicted risks."},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate.html","id":"survival-analysis-model","dir":"Articles","previous_headings":"Example 1: validating an existing prediction model on new data","what":"Survival analysis model","title":"Introduction to the predRupdate package","text":"example considered validation existing CPM based logistic regression. predRupdate also contains functionality validate CPMs based time--event (survival) models (e.g. Cox proportional hazards model). case, baseline cumulative hazard model also specified, along regression coefficients. many cases, baseline cumulative hazard existing CPM reported “full”, rather estimates baseline cumulative hazard given set follow-times. use predRupdate, users specify baseline cumulative hazard times one wishes make predictions (validate/update model). example, suppose existing CPM developed using Cox proportional hazards predict time--death surgery, following predictor parameters (log hazard ratios): Table coefficients existing time--event regression prediction model following baseline cumulative hazard reported discrete times months 1-5 post surgery: Table baseline cumulative hazard can use pred_validate() function validate model 1, 2, 3, 4 5 months follow-new dataset. achieve , one follows similar syntax logistic model. main difference one needs specify time follow-’d like validate model - time must also available baseline cumulative hazard provided. , see existing model -predicts mean risk 5-months (observed:Expected Ratio greater 1), evidence -fitting. model also poor discrimination (Harrell C). can also see plot distribution predicted risks, calibration plot, follows:","code":"# create a data.frame of the model coefficients, with columns being variables coefs_table <- data.frame(\"Age\" = 0.007,                           \"SexM\" = 0.225,                           \"Smoking_Status\" = 0.685,                           \"Diabetes\" = 0.425,                           \"Creatinine\" = 0.587)  #pass this into pred_input_info() Existing_TTE_Model <- pred_input_info(model_type = \"survival\",                                       model_info = coefs_table,                                       cum_hazard = BH_table) #where BH_table is the baseline hazard above  #now validate against the time-to-event outcomes in the new dataset: validation_results <- pred_validate(x = Existing_TTE_Model,                                     new_data = SYNPM$ValidationData,                                     survival_time = \"ETime\",                                     event_indicator = \"Status\",                                     time_horizon = 5) summary(validation_results) #> Calibration Measures  #> ---------------------------------  #>                         Estimate Lower 95% Confidence Interval #> Observed:Expected Ratio   1.2211                        1.2002 #> Calibration Slope         0.7129                        0.6580 #>                         Upper 95% Confidence Interval #> Observed:Expected Ratio                        1.2423 #> Calibration Slope                              0.7679 #>  #>  Also examine the calibration plot, if produced.  #>  #> Discrimination Measures  #> ---------------------------------  #>           Estimate Lower 95% Confidence Interval Upper 95% Confidence Interval #> Harrell C   0.5789                        0.5726                        0.5852 #>  #>  Also examine the distribution plot of predicted risks. plot(validation_results)"},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate.html","id":"specifying-the-baseline-cumulative-hazard","dir":"Articles","previous_headings":"Example 1: validating an existing prediction model on new data > Survival analysis model","what":"Specifying the baseline cumulative hazard","title":"Introduction to the predRupdate package","text":"validating existing time--event model, baseline cumulative hazard existing CPM reported (e.g., original model publication). cases, might reported discrete follow-times (like example). Alternatively, entire baseline cumulative hazard curve may presented plot, indeed parametric form baseline cumulative hazard may provided. situations, one extract (plot) calculate (parametric form) baseline cumulative hazard multiple follow-times interest (.e., follow-times one wishes validate model ). However, cases, baseline cumulative hazard existing time--event CPM may reported. situation, one can still use predRupdate validate model. However, limited number metrics produced (.e., metrics require linear predictor, absolute risk predictions given follow-time). Specifically, observed:expected ratio calibration plot produced baseline cumulative hazard provided.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate.html","id":"a-note-on-basehaz-in-r","dir":"Articles","previous_headings":"Example 1: validating an existing prediction model on new data > Survival analysis model > Specifying the baseline cumulative hazard","what":"A note on basehaz() in R","title":"Introduction to the predRupdate package","text":"one fit Cox Proportional Hazards model R (using coxph() survival package), wishes use predRupdate internally validate model, cumulative baseline hazard model must estimated, can done using basehaz() function survival package. situation, care must taken regards centering data. default, coxph() internally scales centers data model fit (see ?survival::coxph() details). , users either pass newdata basehaz() values model covariate set give baseline cumulative hazard (e.g., 0 continuous covariates reference category categorical/factor covariates), make use ‘centrered=FALSE’ option basehaz(). means basehaz() return cumulative baseline hazard centered scaled covariate values (see ?survival::basehaz() details; specifically, ‘centered=TRUE’ argument function). one passes resulting baseline hazard predRupdate package functions, care must taken also scale centre new_data passed predRupdate functions. package functions make attempt checking consistency, users advised ensure baseline cumulative hazard consistent format new data provided validate model. example code illustrates points:","code":"df <- SYNPM$ValidationData  cox_mod <- survival::coxph(survival::Surv(ETime, Status) ~ Age + Creatinine,                             data = df) coefs_table <- data.frame(\"Age\" = coef(cox_mod)[\"Age\"],                           \"Creatinine\" = coef(cox_mod)[\"Creatinine\"])  #example of using basehaz() for uncentered/values: base_haz_zero <- survival::basehaz(cox_mod,                                     newdata = data.frame(\"Age\" = 0,                                                         \"Creatinine\" = 0)) #or use centered=FALSE in survival::basehaz() #base_haz_zero <- survival::basehaz(cox_mod, centered = FALSE)  Existing_TTE_Model <- pred_input_info(model_type = \"survival\",                                       model_info = coefs_table,                                       cum_hazard = data.frame(\"time\" = base_haz_zero$time,                                                               \"hazard\" = base_haz_zero$hazard))  pred_validate(x = Existing_TTE_Model,               new_data = data.frame(\"Age\" = df$Age,                                     \"Creatinine\" = df$Creatinine,                                     \"ETime\" = df$ETime,                                     \"Status\" = df$Status),               survival_time = \"ETime\",               event_indicator = \"Status\",               time_horizon = 5)   #Alternatively, the below code shows how to handle the scaled/centred baseline  # hazard, such that we need to also scale/centre the new_data: base_haz_centred <- survival::basehaz(cox_mod) Existing_TTE_Model <- pred_input_info(model_type = \"survival\",                                       model_info = coefs_table,                                       cum_hazard = data.frame(\"time\" = base_haz_centred$time,                                                               \"hazard\" = base_haz_centred$hazard))  pred_validate(x = Existing_TTE_Model,               new_data = data.frame(\"Age\" = df$Age - mean(df$Age),                                     \"Creatinine\" = df$Creatinine - mean(df$Creatinine),                                     \"ETime\" = df$ETime,                                     \"Status\" = df$Status),               survival_time = \"ETime\",               event_indicator = \"Status\",               time_horizon = 5) #failing to mean-center new_data passed into pred_validate() would give erroneous results."},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate.html","id":"example-2-model-updating-on-new-data","dir":"Articles","previous_headings":"","what":"Example 2: model updating on new data","title":"Introduction to the predRupdate package","text":"validation existing logistic regression model Example 1 , found existing model miscalibrated new data. One strategy handle apply range model updating methods; see vignette(\"predRupdate_technical\") technical discussion methods. illustrate achieve predRupdate, choose apply model re-calibration existing logistic regression model shown Example 1 . Within predRupdate, use pred_update(): One validate updated model using pred_validate(), given updated model new data, -practice performance estimates need adjusted -sample optimism (e.g., using cross-validation bootstrap internal validation): Similar functionality available time--event models, using similar syntax.","code":"# create a data.frame of the model coefficients, with columns being variables coefs_table <- data.frame(\"Intercept\" = -3.995,                            \"Age\" = 0.012,                           \"SexM\" = 0.267,                            \"Smoking_Status\" = 0.751,                           \"Diabetes\" = 0.523,                           \"Creatinine\" = 0.578)  #pass this into pred_input_info() Existing_Logistic_Model <- pred_input_info(model_type = \"logistic\",                                            model_info = coefs_table)  #apply the pred_update function to update the model to the new dataset: Updated_model <- pred_update(Existing_Logistic_Model,                              update_type = \"recalibration\",                              new_data = SYNPM$ValidationData,                              binary_outcome = \"Y\")  summary(Updated_model) #> Original model was updated with type recalibration #> The model updating results are as follows:  #>               Estimate Std. Error #> (Intercept) -0.1579827 0.11713282 #> Slope        0.6495556 0.04629572 #>  #> Updated Model Coefficients  #> =================================  #>   Intercept         Age      SexM Smoking_Status  Diabetes Creatinine #> 1 -2.752957 0.007794668 0.1734314      0.4878163 0.3397176  0.3754432 #>  #> Model Functional Form  #> =================================  #> Age + SexM + Smoking_Status + Diabetes + Creatinine summary(pred_validate(Updated_model,                        new_data = SYNPM$ValidationData,                        binary_outcome = \"Y\")) #> Calibration Measures  #> ---------------------------------  #>                         Estimate Lower 95% Confidence Interval #> Observed:Expected Ratio        1                        0.9664 #> Calibration Intercept          0                       -0.0400 #> Calibration Slope              1                        0.8603 #>                         Upper 95% Confidence Interval #> Observed:Expected Ratio                        1.0347 #> Calibration Intercept                          0.0400 #> Calibration Slope                              1.1397 #>  #>  Also examine the calibration plot, if produced.  #>  #> Discrimination Measures  #> ---------------------------------  #>     Estimate Lower 95% Confidence Interval Upper 95% Confidence Interval #> AUC   0.5816                        0.5703                        0.5928 #>  #>  #> Overall Performance Measures  #> ---------------------------------  #> Cox-Snell R-squared: 0.0095 #> Nagelkerke R-squared: 0.0171 #> Brier Score (CI): 0.1203 (0.1169, 0.1237) #>  #>  Also examine the distribution plot of predicted risks."},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate.html","id":"example-3-model-aggregation-on-new-data","dir":"Articles","previous_headings":"","what":"Example 3: model aggregation on new data","title":"Introduction to the predRupdate package","text":"Sometimes, might multiple existing CPMs available prediction task (e.g., existing models developed across different countries, aiming predict outcome). , model aggregation methods can used pool existing CPMs single model new data; see vignette(\"predRupdate_technical\") technical discussion methods. implement methods within predRupdate, first need input information multiple existing models pred_input_info(). row model_info parameter coefficients existing CPM; parameter included given CPM value NA, shown : can use pred_stacked_regression() apply stacked regression aggregate models single model new dataset: One validate updated model using pred_validate(), given updated model new data, -practice performance estimates need adjusted -sample optimism (e.g., using cross-validation bootstrap internal validation): Similar functionality available time--event models.","code":"coefs_table <- data.frame(rbind(c(\"Intercept\" = -3.995,                                   \"Age\" = 0.012,                                   \"SexM\" = 0.267,                                   \"Smoking_Status\" = 0.751,                                   \"Diabetes\" = 0.523,                                   \"Creatinine\" = 0.578),                                 c(\"Intercept\" = -2.282,                                   \"Age\" = NA,                                   \"SexM\" = 0.223,                                   \"Smoking_Status\" = 0.528,                                   \"Diabetes\" = 0.200,                                   \"Creatinine\" = 0.434),                                 c(\"Intercept\" = -3.013,                                   \"Age\" = NA,                                   \"SexM\" = NA,                                   \"Smoking_Status\" = 0.565,                                   \"Diabetes\" = -0.122,                                   \"Creatinine\" = 0.731))) multiple_mods <- pred_input_info(model_type = \"logistic\",                                  model_info = coefs_table) summary(multiple_mods) #> Information about 3 existing model(s) of type 'logistic'  #>  #> Model Coefficients  #> =================================  #> [[1]] #>   Intercept   Age  SexM Smoking_Status Diabetes Creatinine #> 1    -3.995 0.012 0.267          0.751    0.523      0.578 #>  #> [[2]] #>   Intercept  SexM Smoking_Status Diabetes Creatinine #> 2    -2.282 0.223          0.528      0.2      0.434 #>  #> [[3]] #>   Intercept Smoking_Status Diabetes Creatinine #> 3    -3.013          0.565   -0.122      0.731 #>  #>  #> Model Functional Form  #> =================================  #> Model 1: Age + SexM + Smoking_Status + Diabetes + Creatinine #> Model 2: SexM + Smoking_Status + Diabetes + Creatinine #> Model 3: Smoking_Status + Diabetes + Creatinine SR <- pred_stacked_regression(x = multiple_mods,                               new_data = SYNPM$ValidationData,                               binary_outcome = \"Y\") summary(SR) #> Existing models aggregated using stacked regression #> The model stacked regression weights are as follows:  #> (Intercept)         LP1         LP2         LP3  #>  0.02072515  0.48150208  0.12920227  0.16559034  #>  #> Updated Model Coefficients  #> =================================  #>   Intercept         Age      SexM Smoking_Status Diabetes Creatinine #> 1 -2.696639 0.005778025 0.1573732      0.5233854 0.257464  0.4554285 #>  #> Model Functional Form  #> =================================  #> Age + SexM + Smoking_Status + Diabetes + Creatinine summary(pred_validate(SR,                new_data = SYNPM$ValidationData,                binary_outcome = \"Y\")) #> Calibration Measures  #> ---------------------------------  #>                         Estimate Lower 95% Confidence Interval #> Observed:Expected Ratio        1                        0.9664 #> Calibration Intercept          0                       -0.0400 #> Calibration Slope              1                        0.8623 #>                         Upper 95% Confidence Interval #> Observed:Expected Ratio                        1.0347 #> Calibration Intercept                          0.0400 #> Calibration Slope                              1.1377 #>  #>  Also examine the calibration plot, if produced.  #>  #> Discrimination Measures  #> ---------------------------------  #>     Estimate Lower 95% Confidence Interval Upper 95% Confidence Interval #> AUC    0.583                        0.5717                        0.5943 #>  #>  #> Overall Performance Measures  #> ---------------------------------  #> Cox-Snell R-squared: 0.0098 #> Nagelkerke R-squared: 0.0175 #> Brier Score (CI): 0.1203 (0.1169, 0.1237) #>  #>  Also examine the distribution plot of predicted risks."},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate.html","id":"a-note-on-structure-of-new_data","dir":"Articles","previous_headings":"","what":"A note on structure of new_data","title":"Introduction to the predRupdate package","text":"shown , workflow within predRupdate broadly two main stages: () input information existing CPM(s) using pred_input_info(), (ii) make predictions, perform validation, perform model updating conduct model aggregation methods using pred_predict() pred_validate(), pred_update() pred_stacked_regression(), respectively. Stage () requires specification ‘model_info’ parameter (contains information model parameters), stage (ii) requires specification ‘new_data’ one wishes apply existing CPM(s). requirement consistency parameter/coefficient names given ‘model_info’ parameter pred_input_info() names variables “new_data” pred_predict() pred_validate(), pred_update() pred_stacked_regression(). Specifically, coefficient named ‘model_info’ also column ‘new_data’. example, following results error, smoking variable passed model_info pred_input_info() match name smoking variable ‘new_data’ passed pred_predict(). Moreover, particular care given categorical/factor variables within new_data. example, suppose following new_data: , Sex recorded factor variable levels “M” “F”. working functions predRupdate, one must first convert factor variables indicator/dummy variables. provide dummy_vars() within predRupdate assist . example:","code":"# create a data.frame of the model coefficients, with columns being variables coefs_table <- data.frame(\"Intercept\" = -3.995,                            \"Smoking\" = 0.751)  #pass this into pred_input_info() Existing_Logistic_Model <- pred_input_info(model_type = \"logistic\",                                            model_info = coefs_table) try(pred_predict(Existing_Logistic_Model,                   new_data = SYNPM$ValidationData)) #> Error in map_newdata.predinfo_logistic(x = x, new_data = new_data, binary_outcome = binary_outcome,  :  #>   new_data does not contain some of the predictor variables for the model(s) specified within the pminfo object  names(SYNPM$ValidationData) #> [1] \"Age\"            \"SexM\"           \"Smoking_Status\" \"Diabetes\"       #> [5] \"Creatinine\"     \"ETime\"          \"Status\"         \"Y\" new_df <- data.frame(\"Sex\" = as.factor(c(\"M\", \"F\", \"M\", \"M\", \"F\", \"F\", \"M\")),                      \"Smoking_Status\" = c(1, 0, 0, 1, 1, 0, 1)) coefs_table <- data.frame(\"Intercept\" = -3.4,                           \"Sex_M\" = 0.306,                           \"Smoking_Status\" = 0.628) existing_Logistic_Model <- pred_input_info(model_type = \"logistic\",                                            model_info = coefs_table)  #if we try to use functions within predRupdate using new_df it will give an error as Sex is a factor variable: try(pred_predict(existing_Logistic_Model,                   new_data = new_df)) #> Error in map_newdata.predinfo_logistic(x = x, new_data = new_data, binary_outcome = binary_outcome,  :  #>   'new_data' contains factor variables - convert to dummy/indicator variables first  #>  dummy_vars() can help with this  #we must first turn into dummy variables: new_df_indicatorvars <- dummy_vars(new_df) head(new_df_indicatorvars) #>   Smoking_Status Sex_F Sex_M #> 1              1     0     1 #> 2              0     1     0 #> 3              0     0     1 #> 4              1     0     1 #> 5              1     1     0 #> 6              0     1     0  #and then pass to functions within predRupdate; e.g.: pred_predict(existing_Logistic_Model,               new_data = new_df_indicatorvars) #> $LinearPredictor #> [1] -2.466 -3.400 -3.094 -2.466 -2.772 -3.400 -2.466 #>  #> $PredictedRisk #> [1] 0.07827635 0.03229546 0.04335543 0.07827635 0.05885613 0.03229546 0.07827635 #>  #> $Outcomes #> NULL"},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate_splineIllustration.html","id":"preamble","dir":"Articles","previous_headings":"","what":"Preamble","title":"Example of Validating a Model that Includes Spline Terms","text":"primary purpose predRupdate package externally validate existing (previously published) clinical prediction model (CPM) new dataset. Sometimes existing CPMs include spline terms predictor variables non-linear associations. aim vignette overview use predRupdate validate model, intended supplement vignettes package (vignette(\"predRupdate\")).","code":""},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate_splineIllustration.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Example of Validating a Model that Includes Spline Terms","text":"data, called SYNPM, used throughout vignette available within predRupdate package. See “?SYNPM” details data. short, data models included SYNPM synthetic, purposes vignette, imagine one interested predicting someone’s risk mortality surgery. Data available 20000 people, records individuals age, gender, smoking status, diabetes status, Creatinine value time surgery. data includes binary outcome, Y, indicating patient died within 1 month. vignette, imagine situation CPM previously developed (another dataset) predict risk mortality within 1 month surgery, wish validate model dataset test predictive performance (e.g., external validation study). existing model logistic regression model, following predictor variables coefficients (log-odds ratios) reported: Table coefficients existing logistic regression prediction model existing model included Age B-spline (degree 3) 4 degrees freedom. coefficient basis function given table . existing model reported internal knot location 50.09 years, boundary knot locations 36 64 years. now show one can use reported information externally validate model new data using predRupdate package.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate_splineIllustration.html","id":"external-validation","dir":"Articles","previous_headings":"","what":"External Validation","title":"Example of Validating a Model that Includes Spline Terms","text":"first step using predRupdate validate model input model information. start creating data.frame model coefficients, columns predictor variable names. information passed pred_input_info() function input information existing model. See pred_input_info() details. Next, need apply B-spline function (exactly originally published existing model validation) dataset. can R using splines package, passing knot locations reported existing model development: can see creates basis functions, add validation dataset (taking care name columns corresponding coefficients basis function specified ): Now, can validate model validation dataset using pred_validate() normal (see vignette(\"predRupdate\")):","code":"# create a data.frame of the model coefficients, with columns being variables coefs_table <- data.frame(\"Intercept\" = -3.995, #the intercept needs to be named exactly as given here                           \"Age_spline1\" = 0.72918,                           \"Age_spline2\" = 0.06249,                            \"Age_spline3\" = 1.67003,                           \"Age_spline4\" = 0.75348,                           \"SexM\" = 0.47859)  #pass this into pred_input_info() Existing_Logistic_Model <- pred_input_info(model_type = \"logistic\",                                            model_info = coefs_table) summary(Existing_Logistic_Model) #> Information about 1 existing model(s) of type 'logistic'  #>  #> Model Coefficients  #> =================================  #>   Intercept Age_spline1 Age_spline2 Age_spline3 Age_spline4    SexM #> 1    -3.995     0.72918     0.06249     1.67003     0.75348 0.47859 #>  #> Model Functional Form  #> =================================  #> Age_spline1 + Age_spline2 + Age_spline3 + Age_spline4 + SexM Age_spline <- splines::bs(SYNPM$ValidationData$Age,                           knots = c(50.09),                           Boundary.knots = c(36, 64))  head(Age_spline) #>              1         2          3            4 #> [1,] 0.3274396 0.4868261 0.18474109 0.0000000000 #> [2,] 0.1739705 0.4823196 0.34237812 0.0013318088 #> [3,] 0.1847176 0.4873202 0.32718198 0.0007802354 #> [4,] 0.2026126 0.4936276 0.30350207 0.0002577483 #> [5,] 0.1404779 0.4598862 0.39461373 0.0050222206 #> [6,] 0.5795287 0.2856465 0.04120013 0.0000000000 ValidationData <- SYNPM$ValidationData ValidationData$Age_spline1 <- Age_spline[,1] ValidationData$Age_spline2 <- Age_spline[,2] ValidationData$Age_spline3 <- Age_spline[,3] ValidationData$Age_spline4 <- Age_spline[,4] validation_results <- pred_validate(x = Existing_Logistic_Model,                                     new_data = ValidationData,                                     binary_outcome = \"Y\") summary(validation_results) #use summary() to obtain a tidy output summary of the model performance #> Calibration Measures  #> ---------------------------------  #>                         Estimate Lower 95% Confidence Interval #> Observed:Expected Ratio   2.9952                        2.8947 #> Calibration Intercept     1.2097                        1.1697 #> Calibration Slope         1.0555                        0.9197 #>                         Upper 95% Confidence Interval #> Observed:Expected Ratio                        3.0992 #> Calibration Intercept                          1.2496 #> Calibration Slope                              1.1913 #>  #>  Also examine the calibration plot, if produced.  #>  #> Discrimination Measures  #> ---------------------------------  #>     Estimate Lower 95% Confidence Interval Upper 95% Confidence Interval #> AUC   0.5854                         0.574                        0.5968 #>  #>  #> Overall Performance Measures  #> ---------------------------------  #> Cox-Snell R-squared: -0.1282 #> Nagelkerke R-squared: -0.23 #> Brier Score (CI): 0.1295 (0.1268, 0.1321) #>  #>  Also examine the distribution plot of predicted risks. validation_results$flex_calibrationplot"},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate_technical.html","id":"preamble","dir":"Articles","previous_headings":"","what":"Preamble","title":"Technical Background to predRupdate","text":"predRupdate package includes set functions aid validation clinical prediction model (CPM) given dataset, apply various model updating aggregation methods. vignette aims overview technical details methods implemented within predRupdate package. introduction using package, please see vignette(\"predRupdate\").","code":""},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate_technical.html","id":"clinical-prediction-models","dir":"Articles","previous_headings":"","what":"Clinical Prediction Models","title":"Technical Background to predRupdate","text":"Clinical prediction models (CPMs) statistical models aim predict presence (diagnostic models) future occurrence (prognostic models) outcome interest individual, using information (predictor variables) available individual time prediction made. example, might use someone’s age, sex, smoking status family medical history predict risk developing cardiovascular disease next ten years. models can used aid clinical decision-making, form cornerstone decision support systems, underpin clinical audit feedback tasks. usual stages production CPMs : () model development internal validation, (ii) external validation new data, potentially updating needed, (iii) impact assessment. summarised table : Phases clinical prediction model production aim predRupdate provide tools stage (ii). Specifically, package intended situation CPM already developed (e.g., model available literature), one wishes apply model new dataset validation, updating, . package assumes one access reported model parameters (required make prediction risk new observation) individual participant dataset one wishes apply model. vignette intended detailed tutorial prediction modelling. , refer readers Riley et al. 2019 Steyerberg 2009. Instead, vignette intended describe technical details certain methodologies implemented predRupdate.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate_technical.html","id":"predictive-performance-metrics","dir":"Articles","previous_headings":"","what":"Predictive Performance Metrics","title":"Technical Background to predRupdate","text":"predictive performance CPM summarised calibration, discrimination overall accuracy. provide brief overview technical details implemented predRupdate pred_validate() function, refer readers literature detailed overview (Riley et al. 2019; Steyerberg et al. 2013; Moons et al. 2012; Altman Royston 2000; Van Calster et al. 2016; McLernon et al. 2023).","code":""},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate_technical.html","id":"calibration","dir":"Articles","previous_headings":"Predictive Performance Metrics","what":"Calibration","title":"Technical Background to predRupdate","text":"Calibration agreement predicted risks CPM observed risks validation dataset, across full risk range. primary method assessing calibration produce flexible calibration plot, graphically depicts estimated risk (x-axis) observed probabilities (y-axis). observed probabilities obtained regressing observed outcomes validation dataset linear predictor (calculated individual validation dataset), using loess splines. Specifically, suppose existing (logistic regression) CPM developed (another dataset) predict probability binary outcome, YY. CPM given log(πi1−πi)=β̂0+β̂1Xi,1+β̂2Xi,2+...+β̂PXi,P \\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = \\hat{\\beta}_0 + \\hat{\\beta}_1X_{,1} + \\hat{\\beta}_2X_{,2} + ... + \\hat{\\beta}_PX_{,P} πi=P(Yi=1)\\pi_{} = P(Y_i = 1), β̂0,...β̂P\\hat{\\beta}_{0},...\\hat{\\beta}_{P} estimated set regression coefficients (log odds ratios; taken original development model) Xi,pX_{,p} value predictor variable pp individual ii. linear combination regression coefficients predictor variables linear predictor model. obtain flexible calibration plot model within validation data, pred_validate() fits following model validation data: log(πi1−πi)=α0+s(LPi) \\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = \\alpha_0 + s(LP_i) s(.)s(.) smooth function; pred_validate() natural cubic spline. model used obtain observed probabilities individual validation dataset, plotted corresponding predicted risks obtained CPM. resulting curve close diagonal (y=x line) indicates predicted risks correspond well observed proportions. pred_validate(), histogram predicted risk distribution overlaid calibration plot, visually summarise probability distribution. validating existing time--event CPM, pred_validate() produces flexible calibration plot using methods similar described logistic regression models. , observed probabilities obtained fitting Cox proportional hazards model regress linear predictor model (natural cubic spline) time--event outcome validation dataset. time horizon must also specified (.e., time follow-assess calibration). plot can produced existing time--event CPM cumulative baseline hazard model supplied. Alongside flexible calibration plots, pred_validate() also calculates calibration slope. calibration slope (ideal value 1) indicates level -fitting model, values less 1 indicating -fitting. pred_validate() estimated fitting logistic regression model (existing CPM logistic model) Cox proportion hazards model (existing CPM survival model) observed outcomes validation dataset linear predictor CPM covariate. Finally, calibration---large summarises close mean predicted risk mean outcome proportion validation dataset. validating logistic regression CPM, quantified using calibration intercept, estimated using model estimating calibration slope, slope fixed unity. , calibration intercept less 0 indicate mean predicted risk higher observed outcome proportion. validating time--event (survival) CPM, calibration---large quantified observed:expected ratio (ideal value 1) fixed time horizon. , observed proportion obtained using Kaplan-Meier estimate. metric can produced existing time--event CPM cumulative baseline hazard model supplied predicted risks time horizon can calculated.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate_technical.html","id":"discrimination","dir":"Articles","previous_headings":"Predictive Performance Metrics","what":"Discrimination","title":"Technical Background to predRupdate","text":"Discrimination CPM ability model differentiate experience outcome ; .e., model estimate higher predicted risk, average, experience outcome, compared experience outcome. validating logistic regression CPMs, pred_validate() calculates area receiver operating characteristic curve (AUC) CPM. validating time--event (survival) CPMs, pred_validate() calculates Harrell’s C-statistic. AUC/ C-statistic 0.5 indicate discrimination better chance, whereas value 1 indicates perfect calibration.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate_technical.html","id":"overall-accuracy","dir":"Articles","previous_headings":"Predictive Performance Metrics","what":"Overall Accuracy","title":"Technical Background to predRupdate","text":"validating logistic regression model, pred_validate() also produces two additional metrics overall accuracy model. first Cox-Snell Nagelkerke R-squared values. , higher R-squared values indicate better overall performance model. Cox-Snell R-squared estimated RCS2=1−exp(−LRn) R^{2}_{CS} = 1 - \\exp\\left(\\frac{-LR}{n}\\right) LRLR likelihood ratio statistic, nn size validation dataset. Specifically, LR=−2(Lnull−Lmodel) LR = -2(L_{null} - L_{model}) LmodelL_{model} log-likelihood CPM validation dataset, LnullL_{null} log-likelihood intercept-model validation dataset. Nagelkerke R-squared scaled version Cox-Snell R-squared, 1 ‘best’ value (unlike Cox-Snell R-squared). Finally, Brier score logistic regression CPM also calculated, average squared difference observed outcome predicted risks model.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate_technical.html","id":"model-updating-methods","dir":"Articles","previous_headings":"","what":"Model Updating Methods","title":"Technical Background to predRupdate","text":"Upon validating existing CPM new data (external validation) uncommon find models predictive performance deteriorates. Rather developing new model, alternative strategy apply model updating methods. See Moons et al. 2012 Su et al. 2018 detailed overview methods. extent model updating depends issues identified model validation. model validation identifies CPM poor calibration---large, simple updating strategy “intercept update”. logistic regression CPM, pred_update() fits following model new dataset using maximum likelihood estimation: log(πi1−πi)=α0+LPi=α0+(β̂0+β̂1Xi,1+...+β̂PXi,P) \\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = \\alpha_0 + LP_i = \\alpha_0 + (\\hat{\\beta}_0 + \\hat{\\beta}_1X_{,1} + ... + \\hat{\\beta}_PX_{,P}) , α0\\alpha_0 serves update intercept original model mean predicted risk (updated) CPM matches observed event proportion new dataset. Specifically, new intercept α0+β̂0\\alpha_0 + \\hat{\\beta}_0. terms (β1,...,βP\\beta_{1},...,\\beta_{P}) remain originally published. Often, original model also demonstrate elements -fitting (.e., calibration slope model <1 validation data). case, model can re-calibrated new dataset. logistic regression CPM, pred_update() fits following model new dataset using maximum likelihood estimation: log(πi1−πi)=α0+α1LPi=α0+α1(β̂0+β̂1Xi,1+...+β̂PXi,P) \\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = \\alpha_0 + \\alpha_1LP_i = \\alpha_0 + \\alpha_1(\\hat{\\beta}_0 + \\hat{\\beta}_1X_{,1} + ... + \\hat{\\beta}_PX_{,P}) effect multiplying original model coefficient α1\\alpha_1. Specifically, new (updated) regression coefficients α1×βp\\alpha_1 \\times \\beta{p}, new model intercept α0+(α1×β̂0)\\alpha_0 + (\\alpha_1 \\times \\hat{\\beta}_0). Neither methods alter discrimination model within new dataset. , one option refit model new dataset. , one fit following model new dataset using maximum likelihood estimation: log(πi1−πi)=α̂0+α̂1Xi,1+α̂2Xi,2+...+α̂PXi,P \\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = \\hat{\\alpha}_0 + \\hat{\\alpha}_1X_{,1} + \\hat{\\alpha}_2X_{,2} + ... + \\hat{\\alpha}_PX_{,P} , α0,...,αP\\alpha_{0},...,\\alpha_{P} become new regression coefficients updated model. also less extreme version model refitting, one re-estimates certain parameters. implemented package near future. describe updating methods logistic regression models, predRupdate also implements approaches time--event (survival) CPMs. principles similar, expect underlying model changed Cox proportional hazards model (parametric/ flexible parametric methods added future). Specifically, “intercept update” survival (time--event) CPM, following form: h(t|X)=h0(t)exp(LPi)=h0(t)exp(β̂1Xi,1+...+β̂PXi,P) h(t|X) = h_0(t)\\exp(LP_i) = h_0(t)\\exp(\\hat{\\beta}_1X_{,1} + ... + \\hat{\\beta}_PX_{,P}) effect re-estimating baseline hazard new data. re-calibration, updated survival (time--event) CPM : h(t|X)=h0(t)exp(α1LPi)=h0(t)exp(α1(β̂1Xi,1+...+β̂PXi,P)) h(t|X) = h_0(t)\\exp(\\alpha_1LP_i) = h_0(t)\\exp(\\alpha_1(\\hat{\\beta}_1X_{,1} + ... + \\hat{\\beta}_PX_{,P}))  effect multiplying original model coefficient (log-hazard ratios) α1\\alpha_1, estimating new baseline hazard new data.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate_technical.html","id":"model-aggregation-methods","dir":"Articles","previous_headings":"","what":"Model Aggregation Methods","title":"Technical Background to predRupdate","text":"situations, instances multiple existing CPMs available prediction task (e.g., existing models developed across different countries). , model aggregation methods can used pool existing CPMs single model new data. Various methods exist (Martin et al. 2017), predRupdate currently implementing stacked regression (Debray et al. 2014) pred_stacked_regression(). methods added future. Specifically, suppose collection MM existing logistic regression CPMs, aim predict binary outcome, YY, developed different populations j=1,...,Mj=1,...,M. models may contain different predictor variables. model linear predictor (LP) given log(πi1−πi)=β̂0,j+β̂1,jXi,1+β̂2,jXi,2+...+β̂P,jXi,P=LPi,j \\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = \\hat{\\beta}_{0,j} + \\hat{\\beta}_{1,j}X_{,1} + \\hat{\\beta}_{2,j}X_{,2} + ... + \\hat{\\beta}_{P,j}X_{,P} = LP_{,j} notation, given variable included given CPM, corresponding β\\beta equal zero. One can apply models observation ii validation set calculate set MM linear predictors. pred_stacked_regression() applies stacked regression regressing set linear predictors observed outcome validation dataset log(πi1−πi)=γ0+γ1LPi,1+...+γMLPi,M \\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = \\gamma_0 + \\gamma_1LP_{,1} + ... + \\gamma_MLP_{,M} equation can re-arranged express terms set new (aggregated) predictor coefficients PP predictor variables. Given MM existing models aim predict outcome, high level co-linearity set MM linear predictors. Therefore, suggestions fit stacked regression model constraint γ1,...γM\\gamma_1,...\\gamma_M non-negative. pred_stacked_regression() implements stacked regression without constraint. pred_stacked_regression() can also implement stacked regression MM existing time--event (survival) CPMs. technical details similar described logistic models, exception underlying model changed Cox proportional hazards model.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/articles/predRupdate_technical.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Technical Background to predRupdate","text":"Riley RD, et al. Prognosis Research Healthcare: Oxford University Press; 2019 Steyerberg EW. Clinical Prediction Models: Springer New York; 2009 Riley RD, Hayden JA, Steyerberg EW, et al. Prognosis research strategy (PROGRESS) 2: Prognostic factor research. PLoS Med 2013;10:e1001380–e1001380 Steyerberg EW, Moons KG, van der Windt DA, et al. Prognosis research strategy (PROGRESS) 3: prognostic model research. PLoS Med 2013;10:e1001381–e1001381 Moons KGM, Kengne AP, Grobbee DE, et al Risk prediction models: II. External validation, model updating, impact assessment Heart 2012;98:691-698. Altman, D.G. Royston, P. mean validating prognostic model?. Statist. Med., 2000;19:453-473. Van Calster, B., Nieboer, D., Vergouwe, Y., et al. calibration hierarchy risk models defined: utopia empirical data. J. Clin. Epidemiol. 2016;74:167-176 McLernon, D.J., Giardiello, D., Van Calster, B. et al. Assessing Performance Clinical Usefulness Prediction Models Survival Outcomes: Practical Guidance Cox Proportional Hazards Models. Ann Intern Med. 2023;176:105-114 Su T-L, Jaki T, Hickey GL, Buchan , Sperrin M. review statistical updating methods clinical prediction models. Statistical Methods Medical Research. 2018;27(1):185-197 Martin, G.P., Mamas, M.., Peek, N. et al. Clinical prediction defined populations: simulation study investigating aggregate existing models. BMC Med Res Methodol. 2017;17(1) Debray TP, Koffijberg H, Nieboer D, Vergouwe Y, Steyerberg EW, Moons KG. Meta-analysis aggregation multiple published prediction models. Stat Med. 2014;33(14):2341-62","code":""},{"path":"https://glenmartin31.github.io/predRupdate/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Glen P. Martin. Author, maintainer, copyright holder. David Jenkins. Author, copyright holder. Matthew Sperrin. Author, copyright holder.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Martin G, Jenkins D, Sperrin M (2025). predRupdate: Prediction Model Validation Updating. R package version 0.2.1, https://github.com/GlenMartin31/predRupdate.","code":"@Manual{,   title = {predRupdate: Prediction Model Validation and Updating},   author = {Glen P. Martin and David Jenkins and Matthew Sperrin},   year = {2025},   note = {R package version 0.2.1},   url = {https://github.com/GlenMartin31/predRupdate}, }"},{"path":"https://glenmartin31.github.io/predRupdate/index.html","id":"predrupdate-","dir":"","previous_headings":"","what":"Prediction Model Validation and Updating","title":"Prediction Model Validation and Updating","text":"goal predRupdate provide suite functions validating existing (.e. previously developed) prediction/ prognostic model, applying model updating methods said model, according available dataset.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Prediction Model Validation and Updating","text":"package can installed CRAN follows:","code":"install.packages(\"predRupdate\")"},{"path":"https://glenmartin31.github.io/predRupdate/index.html","id":"development-version","dir":"","previous_headings":"","what":"Development version","title":"Prediction Model Validation and Updating","text":"can install development version predRupdate GitHub ::","code":"# install.packages(\"devtools\") devtools::install_github(\"GlenMartin31/predRupdate\")"},{"path":"https://glenmartin31.github.io/predRupdate/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Prediction Model Validation and Updating","text":"One main use package externally validate existing (previously developed) prediction model. can achieved following code:","code":"# create a data.frame of the model coefficients, with columns being variables coefs_table <- data.frame(\"Intercept\" = -3.4,                           \"SexM\" = 0.306,                           \"Smoking_Status\" = 0.628,                           \"Diabetes\" = 0.499,                           \"Creatinine\" = 0.538)  #pass this into pred_input_info() Existing_Logistic_Model <- pred_input_info(model_type = \"logistic\",                                            model_info = coefs_table) summary(Existing_Logistic_Model)  #validate this model against an available dataset pred_validate(x = Existing_Logistic_Model,               new_data = SYNPM$ValidationData,               binary_outcome = \"Y\")"},{"path":"https://glenmartin31.github.io/predRupdate/index.html","id":"getting-help","dir":"","previous_headings":"","what":"Getting help","title":"Prediction Model Validation and Updating","text":"encounter bug, please file issue minimal reproducible example GitHub.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/SYNPM.html","id":null,"dir":"Reference","previous_headings":"","what":"SYNthetic Prediction Models (SYNPM) and Validation dataset — SYNPM","title":"SYNthetic Prediction Models (SYNPM) and Validation dataset — SYNPM","text":"list containing: (1) information (synthetic) existing prediction models (representing available/published, want validate another independent dataset); (2) synthetic dataset wish validate/update models .","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/SYNPM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SYNthetic Prediction Models (SYNPM) and Validation dataset — SYNPM","text":"","code":"SYNPM"},{"path":"https://glenmartin31.github.io/predRupdate/reference/SYNPM.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"SYNthetic Prediction Models (SYNPM) and Validation dataset — SYNPM","text":"list six elements. first element data frame information three existing binary (logistic regression) models binary outcome one year second element data frame information three existing time--event (Cox) models time--event outcome third, fourth fifth elements cumulative baseline hazard information three time--event model sixth element (synthetic) validation dataset want validate existing models. dataset 20000 rows 8 variables: Age age individual baseline SexM sex individual (1 = male; 0 = female) Smoking_Status Indicates whether individual smoker (1=previous/ current smoker, 0=non-smoker) Diabetes Indicates whether individual diabetes (1=diabetic, 0=diabetic) Creatinine Creatinine value individual (mg/dL) ETime time baseline either event censoring Status Indicator whether patient experienced event censored ETime Y Binary indicator whether individual experienced event 1 time-unit","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/SYNPM.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"SYNthetic Prediction Models (SYNPM) and Validation dataset — SYNPM","text":"Simulated Data; see https://github.com/GlenMartin31/predRupdate","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/dummy_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Create dummy variables for all categorical/factor variables in a data.frame — dummy_vars","title":"Create dummy variables for all categorical/factor variables in a data.frame — dummy_vars","text":"Create dummy/indicator variables categorical variables data.frame. Can used pre-processing step calling functions within package.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/dummy_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create dummy variables for all categorical/factor variables in a data.frame — dummy_vars","text":"","code":"dummy_vars(df)"},{"path":"https://glenmartin31.github.io/predRupdate/reference/dummy_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create dummy variables for all categorical/factor variables in a data.frame — dummy_vars","text":"df data.frame make dummy variables categorical/factor variable, based contrasts.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/dummy_vars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create dummy variables for all categorical/factor variables in a data.frame — dummy_vars","text":"data.frame matching df categorical variable df replaced indicator variables. combinations indicator/dummy variable returned. Naming convention new dummy variables variable_level. example, factor variable df named \"colour\" levels \"red\", \"green\" \"purple\" replaced three columns (new dummy variables), named colour_red,  colour_green colour_purple.","code":""},{"path":[]},{"path":"https://glenmartin31.github.io/predRupdate/reference/dummy_vars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create dummy variables for all categorical/factor variables in a data.frame — dummy_vars","text":"","code":"dummy_vars(data.frame(\"Colour\" = factor(sample(c(\"red\",                                                  \"azure\",                                                  \"green\",                                                  \"white\"),                                               500,                                               replace = TRUE)))) #>     Colour_azure Colour_green Colour_red Colour_white #> 1              0            0          0            1 #> 2              0            1          0            0 #> 3              0            0          1            0 #> 4              1            0          0            0 #> 5              0            1          0            0 #> 6              0            1          0            0 #> 7              0            1          0            0 #> 8              0            0          0            1 #> 9              1            0          0            0 #> 10             0            0          1            0 #> 11             0            0          1            0 #> 12             0            0          1            0 #> 13             0            1          0            0 #> 14             0            0          0            1 #> 15             0            1          0            0 #> 16             0            0          1            0 #> 17             1            0          0            0 #> 18             1            0          0            0 #> 19             0            1          0            0 #> 20             0            1          0            0 #> 21             1            0          0            0 #> 22             0            1          0            0 #> 23             0            0          1            0 #> 24             0            0          1            0 #> 25             0            0          0            1 #> 26             0            0          1            0 #> 27             1            0          0            0 #> 28             1            0          0            0 #> 29             0            1          0            0 #> 30             0            1          0            0 #> 31             0            0          0            1 #> 32             0            0          0            1 #> 33             1            0          0            0 #> 34             0            1          0            0 #> 35             0            0          1            0 #> 36             1            0          0            0 #> 37             0            1          0            0 #> 38             0            1          0            0 #> 39             0            0          0            1 #> 40             0            0          1            0 #> 41             1            0          0            0 #> 42             0            0          1            0 #> 43             1            0          0            0 #> 44             0            1          0            0 #> 45             1            0          0            0 #> 46             0            0          0            1 #> 47             0            0          1            0 #> 48             1            0          0            0 #> 49             0            0          1            0 #> 50             0            0          0            1 #> 51             0            0          0            1 #> 52             1            0          0            0 #> 53             0            1          0            0 #> 54             0            0          1            0 #> 55             1            0          0            0 #> 56             1            0          0            0 #> 57             0            1          0            0 #> 58             1            0          0            0 #> 59             0            0          1            0 #> 60             0            0          1            0 #> 61             0            1          0            0 #> 62             1            0          0            0 #> 63             0            0          1            0 #> 64             0            0          0            1 #> 65             0            0          1            0 #> 66             0            0          0            1 #> 67             0            0          0            1 #> 68             0            1          0            0 #> 69             0            0          0            1 #> 70             0            0          0            1 #> 71             0            0          0            1 #> 72             0            1          0            0 #> 73             1            0          0            0 #> 74             0            1          0            0 #> 75             1            0          0            0 #> 76             0            1          0            0 #> 77             1            0          0            0 #> 78             0            1          0            0 #> 79             1            0          0            0 #> 80             0            0          0            1 #> 81             1            0          0            0 #> 82             0            0          1            0 #> 83             0            1          0            0 #> 84             1            0          0            0 #> 85             1            0          0            0 #> 86             0            1          0            0 #> 87             0            0          1            0 #> 88             1            0          0            0 #> 89             0            0          0            1 #> 90             0            0          0            1 #> 91             0            0          1            0 #> 92             0            0          0            1 #> 93             0            0          1            0 #> 94             0            1          0            0 #> 95             0            0          0            1 #> 96             1            0          0            0 #> 97             0            0          1            0 #> 98             1            0          0            0 #> 99             1            0          0            0 #> 100            1            0          0            0 #> 101            0            1          0            0 #> 102            0            0          0            1 #> 103            1            0          0            0 #> 104            0            0          0            1 #> 105            1            0          0            0 #> 106            1            0          0            0 #> 107            0            0          1            0 #> 108            0            1          0            0 #> 109            0            1          0            0 #> 110            0            0          0            1 #> 111            0            0          1            0 #> 112            0            0          1            0 #> 113            0            0          1            0 #> 114            0            0          1            0 #> 115            1            0          0            0 #> 116            0            0          1            0 #> 117            0            0          1            0 #> 118            0            0          1            0 #> 119            1            0          0            0 #> 120            0            0          0            1 #> 121            0            0          1            0 #> 122            0            1          0            0 #> 123            0            1          0            0 #> 124            0            0          1            0 #> 125            0            0          0            1 #> 126            0            1          0            0 #> 127            0            1          0            0 #> 128            0            0          0            1 #> 129            1            0          0            0 #> 130            0            0          0            1 #> 131            0            0          1            0 #> 132            0            1          0            0 #> 133            0            0          1            0 #> 134            0            1          0            0 #> 135            0            0          1            0 #> 136            1            0          0            0 #> 137            0            0          1            0 #> 138            0            0          1            0 #> 139            0            0          1            0 #> 140            0            0          1            0 #> 141            0            1          0            0 #> 142            0            0          1            0 #> 143            1            0          0            0 #> 144            0            1          0            0 #> 145            0            0          0            1 #> 146            0            1          0            0 #> 147            0            0          0            1 #> 148            1            0          0            0 #> 149            0            0          1            0 #> 150            1            0          0            0 #> 151            1            0          0            0 #> 152            0            1          0            0 #> 153            0            0          0            1 #> 154            0            1          0            0 #> 155            0            0          0            1 #> 156            0            0          1            0 #> 157            1            0          0            0 #> 158            0            0          0            1 #> 159            0            0          1            0 #> 160            0            0          0            1 #> 161            0            1          0            0 #> 162            0            0          1            0 #> 163            0            0          0            1 #> 164            0            0          1            0 #> 165            0            1          0            0 #> 166            0            1          0            0 #> 167            0            0          1            0 #> 168            1            0          0            0 #> 169            0            1          0            0 #> 170            0            0          0            1 #> 171            0            1          0            0 #> 172            0            1          0            0 #> 173            1            0          0            0 #> 174            0            0          0            1 #> 175            1            0          0            0 #> 176            0            0          1            0 #> 177            0            0          0            1 #> 178            0            0          0            1 #> 179            0            1          0            0 #> 180            1            0          0            0 #> 181            0            0          0            1 #> 182            1            0          0            0 #> 183            0            0          1            0 #> 184            1            0          0            0 #> 185            0            0          1            0 #> 186            1            0          0            0 #> 187            0            1          0            0 #> 188            0            0          0            1 #> 189            0            0          1            0 #> 190            1            0          0            0 #> 191            1            0          0            0 #> 192            1            0          0            0 #> 193            0            0          1            0 #> 194            0            0          1            0 #> 195            0            1          0            0 #> 196            1            0          0            0 #> 197            0            0          1            0 #> 198            1            0          0            0 #> 199            0            0          0            1 #> 200            0            0          0            1 #> 201            0            1          0            0 #> 202            0            0          0            1 #> 203            0            0          0            1 #> 204            0            0          1            0 #> 205            0            0          1            0 #> 206            0            1          0            0 #> 207            0            1          0            0 #> 208            0            0          1            0 #> 209            0            0          0            1 #> 210            0            0          0            1 #> 211            1            0          0            0 #> 212            0            0          0            1 #> 213            0            1          0            0 #> 214            0            0          1            0 #> 215            0            0          0            1 #> 216            0            0          1            0 #> 217            1            0          0            0 #> 218            0            0          1            0 #> 219            0            1          0            0 #> 220            0            0          1            0 #> 221            0            1          0            0 #> 222            0            1          0            0 #> 223            0            0          1            0 #> 224            0            0          1            0 #> 225            0            1          0            0 #> 226            0            1          0            0 #> 227            0            1          0            0 #> 228            0            0          1            0 #> 229            0            0          1            0 #> 230            0            0          0            1 #> 231            0            1          0            0 #> 232            0            1          0            0 #> 233            0            1          0            0 #> 234            0            1          0            0 #> 235            1            0          0            0 #> 236            0            0          0            1 #> 237            0            0          0            1 #> 238            0            1          0            0 #> 239            0            1          0            0 #> 240            0            0          0            1 #> 241            0            0          0            1 #> 242            0            0          0            1 #> 243            0            1          0            0 #> 244            0            0          0            1 #> 245            0            0          0            1 #> 246            0            0          0            1 #> 247            0            0          0            1 #> 248            1            0          0            0 #> 249            0            1          0            0 #> 250            1            0          0            0 #> 251            1            0          0            0 #> 252            0            0          0            1 #> 253            0            0          0            1 #> 254            0            0          1            0 #> 255            0            0          1            0 #> 256            1            0          0            0 #> 257            1            0          0            0 #> 258            0            0          1            0 #> 259            0            0          1            0 #> 260            0            1          0            0 #> 261            0            0          1            0 #> 262            0            0          0            1 #> 263            0            1          0            0 #> 264            0            0          0            1 #> 265            0            1          0            0 #> 266            0            1          0            0 #> 267            0            0          0            1 #> 268            0            0          0            1 #> 269            0            1          0            0 #> 270            0            0          1            0 #> 271            0            0          0            1 #> 272            0            0          1            0 #> 273            0            0          1            0 #> 274            0            0          1            0 #> 275            1            0          0            0 #> 276            0            1          0            0 #> 277            0            1          0            0 #> 278            0            0          0            1 #> 279            1            0          0            0 #> 280            0            1          0            0 #> 281            0            0          0            1 #> 282            1            0          0            0 #> 283            0            1          0            0 #> 284            1            0          0            0 #> 285            0            1          0            0 #> 286            1            0          0            0 #> 287            1            0          0            0 #> 288            1            0          0            0 #> 289            1            0          0            0 #> 290            1            0          0            0 #> 291            0            0          1            0 #> 292            0            1          0            0 #> 293            0            0          0            1 #> 294            1            0          0            0 #> 295            1            0          0            0 #> 296            1            0          0            0 #> 297            0            0          1            0 #> 298            0            0          1            0 #> 299            1            0          0            0 #> 300            0            1          0            0 #> 301            0            0          1            0 #> 302            0            0          0            1 #> 303            0            0          0            1 #> 304            1            0          0            0 #> 305            1            0          0            0 #> 306            0            0          0            1 #> 307            1            0          0            0 #> 308            0            0          0            1 #> 309            0            1          0            0 #> 310            1            0          0            0 #> 311            0            1          0            0 #> 312            0            1          0            0 #> 313            0            0          0            1 #> 314            0            0          0            1 #> 315            0            0          0            1 #> 316            0            1          0            0 #> 317            0            0          0            1 #> 318            0            1          0            0 #> 319            1            0          0            0 #> 320            0            0          1            0 #> 321            0            0          0            1 #> 322            1            0          0            0 #> 323            0            1          0            0 #> 324            0            0          1            0 #> 325            0            0          0            1 #> 326            0            1          0            0 #> 327            0            0          0            1 #> 328            0            0          1            0 #> 329            0            0          1            0 #> 330            0            0          1            0 #> 331            0            0          1            0 #> 332            1            0          0            0 #> 333            0            1          0            0 #> 334            0            0          1            0 #> 335            0            1          0            0 #> 336            0            1          0            0 #> 337            1            0          0            0 #> 338            0            0          0            1 #> 339            0            1          0            0 #> 340            0            0          1            0 #> 341            0            1          0            0 #> 342            0            0          1            0 #> 343            0            0          1            0 #> 344            0            0          0            1 #> 345            1            0          0            0 #> 346            1            0          0            0 #> 347            0            1          0            0 #> 348            0            0          1            0 #> 349            1            0          0            0 #> 350            1            0          0            0 #> 351            0            1          0            0 #> 352            0            0          0            1 #> 353            1            0          0            0 #> 354            0            0          0            1 #> 355            0            0          1            0 #> 356            1            0          0            0 #> 357            0            0          0            1 #> 358            0            0          0            1 #> 359            0            1          0            0 #> 360            0            0          1            0 #> 361            0            0          0            1 #> 362            0            0          0            1 #> 363            0            0          0            1 #> 364            0            1          0            0 #> 365            1            0          0            0 #> 366            0            1          0            0 #> 367            0            0          1            0 #> 368            1            0          0            0 #> 369            0            0          1            0 #> 370            0            0          0            1 #> 371            0            1          0            0 #> 372            0            0          0            1 #> 373            1            0          0            0 #> 374            1            0          0            0 #> 375            0            0          0            1 #> 376            0            0          0            1 #> 377            0            0          1            0 #> 378            1            0          0            0 #> 379            0            0          1            0 #> 380            1            0          0            0 #> 381            0            1          0            0 #> 382            0            1          0            0 #> 383            0            1          0            0 #> 384            1            0          0            0 #> 385            1            0          0            0 #> 386            0            0          1            0 #> 387            0            0          0            1 #> 388            0            0          0            1 #> 389            0            1          0            0 #> 390            0            0          0            1 #> 391            0            0          0            1 #> 392            0            1          0            0 #> 393            1            0          0            0 #> 394            1            0          0            0 #> 395            0            1          0            0 #> 396            0            0          0            1 #> 397            1            0          0            0 #> 398            1            0          0            0 #> 399            1            0          0            0 #> 400            0            0          1            0 #> 401            0            0          1            0 #> 402            0            1          0            0 #> 403            0            0          1            0 #> 404            0            0          0            1 #> 405            0            0          0            1 #> 406            1            0          0            0 #> 407            0            0          1            0 #> 408            0            0          1            0 #> 409            0            1          0            0 #> 410            0            0          0            1 #> 411            0            0          1            0 #> 412            0            0          1            0 #> 413            0            0          1            0 #> 414            0            0          0            1 #> 415            0            0          0            1 #> 416            1            0          0            0 #> 417            0            0          0            1 #> 418            0            0          0            1 #> 419            0            1          0            0 #> 420            1            0          0            0 #> 421            0            0          0            1 #> 422            0            1          0            0 #> 423            0            0          0            1 #> 424            0            1          0            0 #> 425            1            0          0            0 #> 426            0            1          0            0 #> 427            1            0          0            0 #> 428            0            0          1            0 #> 429            1            0          0            0 #> 430            0            0          1            0 #> 431            1            0          0            0 #> 432            1            0          0            0 #> 433            0            0          1            0 #> 434            0            0          0            1 #> 435            1            0          0            0 #> 436            0            1          0            0 #> 437            0            1          0            0 #> 438            0            0          0            1 #> 439            1            0          0            0 #> 440            0            0          0            1 #> 441            1            0          0            0 #> 442            0            0          0            1 #> 443            0            1          0            0 #> 444            1            0          0            0 #> 445            1            0          0            0 #> 446            0            1          0            0 #> 447            0            1          0            0 #> 448            0            0          0            1 #> 449            0            0          0            1 #> 450            0            0          1            0 #> 451            0            0          0            1 #> 452            0            0          0            1 #> 453            0            1          0            0 #> 454            1            0          0            0 #> 455            1            0          0            0 #> 456            0            0          1            0 #> 457            1            0          0            0 #> 458            0            0          0            1 #> 459            1            0          0            0 #> 460            0            0          1            0 #> 461            1            0          0            0 #> 462            1            0          0            0 #> 463            1            0          0            0 #> 464            0            0          1            0 #> 465            0            0          1            0 #> 466            0            0          1            0 #> 467            0            0          1            0 #> 468            0            0          0            1 #> 469            0            0          1            0 #> 470            0            0          1            0 #> 471            1            0          0            0 #> 472            0            1          0            0 #> 473            0            0          0            1 #> 474            0            1          0            0 #> 475            0            0          1            0 #> 476            0            0          0            1 #> 477            0            0          1            0 #> 478            0            0          1            0 #> 479            1            0          0            0 #> 480            0            0          0            1 #> 481            0            0          0            1 #> 482            0            0          1            0 #> 483            0            0          0            1 #> 484            1            0          0            0 #> 485            0            1          0            0 #> 486            0            0          1            0 #> 487            0            0          1            0 #> 488            0            0          0            1 #> 489            1            0          0            0 #> 490            0            1          0            0 #> 491            1            0          0            0 #> 492            0            1          0            0 #> 493            1            0          0            0 #> 494            1            0          0            0 #> 495            1            0          0            0 #> 496            0            1          0            0 #> 497            1            0          0            0 #> 498            0            0          1            0 #> 499            1            0          0            0 #> 500            0            1          0            0"},{"path":"https://glenmartin31.github.io/predRupdate/reference/inv_logit.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply the inverse logit function to an input — inv_logit","title":"Apply the inverse logit function to an input — inv_logit","text":"inv_logit applies inverse-logit transformation (expit/ logistic function) convert vector values -Inf Inf, values 0 1. Used convert linear predictor logistic regression model probability.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/inv_logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply the inverse logit function to an input — inv_logit","text":"","code":"inv_logit(x)"},{"path":"https://glenmartin31.github.io/predRupdate/reference/inv_logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply the inverse logit function to an input — inv_logit","text":"x Numeric vector values -Inf Inf.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/inv_logit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply the inverse logit function to an input — inv_logit","text":"Numeric vector probabilities (.e. values 0 1)","code":""},{"path":[]},{"path":"https://glenmartin31.github.io/predRupdate/reference/inv_logit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply the inverse logit function to an input — inv_logit","text":"","code":"inv_logit(-2) #> [1] 0.1192029 inv_logit(c(-2,-1,0,1,2)) #> [1] 0.1192029 0.2689414 0.5000000 0.7310586 0.8807971"},{"path":"https://glenmartin31.github.io/predRupdate/reference/logit.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a logit transformation to an input — logit","title":"Apply a logit transformation to an input — logit","text":"logit applies logit transformation convert vector values 0 1, values -Inf Inf. Used convert probability logistic regression model onto linear predictor scale.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a logit transformation to an input — logit","text":"","code":"logit(p)"},{"path":"https://glenmartin31.github.io/predRupdate/reference/logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a logit transformation to an input — logit","text":"p Numeric vector probabilities (.e. values 0 1) transformed.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/logit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a logit transformation to an input — logit","text":"numeric vector, values -Inf Inf","code":""},{"path":[]},{"path":"https://glenmartin31.github.io/predRupdate/reference/logit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a logit transformation to an input — logit","text":"","code":"logit(0.5) #> [1] 0 logit(c(0.1, 0.2, 0.3)) #> [1] -2.1972246 -1.3862944 -0.8472979"},{"path":"https://glenmartin31.github.io/predRupdate/reference/map_newdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Map new data to a predinfo object — map_newdata","title":"Map new data to a predinfo object — map_newdata","text":"function takes predinfo object applies (maps) new data object check consistency two. function usually called directly, rather within  functions within package, pred_predict.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/map_newdata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map new data to a predinfo object — map_newdata","text":"","code":"map_newdata(   x,   new_data,   binary_outcome = NULL,   survival_time = NULL,   event_indicator = NULL )"},{"path":"https://glenmartin31.github.io/predRupdate/reference/map_newdata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map new data to a predinfo object — map_newdata","text":"x object class \"predinfo\". new_data data.frame upon prediction model applied (subsequent validation/model updating/model aggregation). binary_outcome Character variable giving name column new_data represents observed binary outcomes (coded 0 1 non-event event, respectively). relevant model_type=\"logistic\"; leave NULL otherwise. Leave NULL new_data contain outcomes. survival_time Character variable giving name column new_data represents observed survival times. relevant model_type=\"survival\"; leave NULL otherwise. Leave NULL new_data contain survival outcomes. event_indicator Character variable giving name column new_data represents observed survival indicator (1 event, 0 censoring). relevant model_type=\"survival\"; leave NULL otherwise. Leave NULL new_data contain survival outcomes.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/map_newdata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map new data to a predinfo object — map_newdata","text":"Returns list predinfo object, new_data, outcomes.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/map_newdata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Map new data to a predinfo object — map_newdata","text":"function maps new dataset onto pred_info object. new dataset might validation dataset (test performance existing prediction model) /might dataset one wishes apply model updating methods revise model. case, specified new_data data.frame. row observation (e.g. patient) variable/column predictor variable. predictor variables need include (minimum) predictor variables included existing prediction model (.e., variable names supplied pred_input_info, model_info parameter, must match name variables new_data). factor variables within new_data must converted dummy (0/1) variables calling function. dummy_vars can help . binary_outcome, survival_time event_indicator used specify outcome variable(s) within new_data, relevant (use binary_outcome model_type = \"logistic\", use survival_time event_indicator model_type = \"survival\"). example, validating existing model, inputs specify columns new_data used assessing predictive performance predictions validation dataset. new_data contain outcomes, leave inputs default NULL.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/map_newdata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map new data to a predinfo object — map_newdata","text":"","code":"#as above, this function is not usually called directly, but an example of #such use is: model1 <- pred_input_info(model_type = \"logistic\",                           model_info = SYNPM$Existing_logistic_models[1,]) map_newdata(x = model1,             new_data = SYNPM$ValidationData[1:10,],             binary_outcome = \"Y\") #> $modelinfo #>  #>  Formula:  #> ~Age + SexM + Smoking_Status + Diabetes + Creatinine #> <environment: 0x56359ee84738> #>  #>  Coefficients:  #>   Intercept        Age      SexM Smoking_Status  Diabetes Creatinine #> 1 -3.995452 0.01150886 0.2673809      0.7511888 0.5230999  0.5781238 #>  #> $PredictionData #>         Age SexM Smoking_Status Diabetes Creatinine      ETime Status Y #> 1  48.68421    1              0        0  0.4847849 5.00000000      0 0 #> 2  51.62041    1              0        0  1.0440606 0.02824273      1 1 #> 3  51.37057    0              0        0  0.6682031 5.00000000      0 0 #> 4  50.97524    1              0        1  1.2498120 2.77747285      1 0 #> 5  52.47209    1              0        0  1.4186517 5.00000000      0 0 #> 6  43.69205    1              0        0  0.6271332 5.00000000      0 0 #> 7  49.92449    1              0        0  0.5669761 2.99792812      1 0 #> 8  42.56161    0              0        0  1.7943725 3.19669111      1 0 #> 9  57.96719    0              0        0  1.2668577 2.78071011      1 0 #> 10 51.18527    0              0        0  0.2766686 0.29270868      1 1 #>  #> $Outcomes #>  [1] 0 1 0 0 0 0 0 0 0 1 #>"},{"path":"https://glenmartin31.github.io/predRupdate/reference/predRupdate-package.html","id":null,"dir":"Reference","previous_headings":"","what":"predRupdate: Prediction Model Validation and Updating — predRupdate-package","title":"predRupdate: Prediction Model Validation and Updating — predRupdate-package","text":"Evaluate predictive performance existing (.e. previously developed) prediction/ prognostic model given relevant information existing prediction model (e.g. coefficients) new dataset. Provides range model updating methods help tailor existing model new dataset; see Su et al. (2018) doi:10.1177/0962280215626466 . Techniques aggregate multiple existing prediction models new data also provided; see Debray et al. (2014) doi:10.1002/sim.6080  Martin et al. (2018) doi:10.1002/sim.7586 ).","code":""},{"path":[]},{"path":"https://glenmartin31.github.io/predRupdate/reference/predRupdate-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"predRupdate: Prediction Model Validation and Updating — predRupdate-package","text":"Maintainer: Glen P. Martin glen.martin31@gmail.com (ORCID) [copyright holder] Authors: David Jenkins david.jenkins-5@manchester.ac.uk [copyright holder] Matthew Sperrin matthew.sperrin@manchester.ac.uk [copyright holder]","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_input_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Input information about an existing prediction model — pred_input_info","title":"Input information about an existing prediction model — pred_input_info","text":"Input coefficient information one multiple existing prediction model(s), use functions package.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_input_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Input information about an existing prediction model — pred_input_info","text":"","code":"pred_input_info(   model_type = c(\"logistic\", \"survival\"),   model_info,   cum_hazard = NULL )"},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_input_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Input information about an existing prediction model — pred_input_info","text":"model_type specifies type model existing prediction model based ; possible options : \"logistic\" indicates existing model based logistic regression model (default) \"survival\" indicates existing model based survival regression model multiple models entered, models need type - otherwise call function multiple times type model. model_info data.frame contains coefficients existing prediction model(s). column predictor variable (name column name predictor variable), values coefficients, taken exactly published existing prediction model(s). Multiple existing prediction models specified entering multiple rows. predictor variable present given model enter cell data.frame NA. See examples. cum_hazard data.frame two columns: (1) time, (2) estimated cumulative baseline hazard time. first column (time) named 'time' second (cumulative baseline hazard) named 'hazard'. relevant model_type \"survival\"; leave NULL otherwise. multiple existing models entered, model_type = survival, cum_hazard supplied list length equal number models.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_input_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Input information about an existing prediction model — pred_input_info","text":"pred_input_info returns object class \"predinfo\", child classes per model_type. standardised format, can used functions package. object class \"predinfo\" list containing following components: M = number existing models information entered model_type = type model existing prediction model based upon (\"logistic\" \"survival\") coefs = set (previously estimated) coefficients predictor variable coef_names = gives names predictor variable formula = functional form model's linear predictor cum_hazard = supplied, cumulative baseline hazard existing model(s)","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_input_info.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Input information about an existing prediction model — pred_input_info","text":"function structure relevant information one existing prediction model(s) standardised format, can used within functions package. First, existing prediction model(s) functional form (.e. linear predictor model); taken linear combination variables specified columns model_info. Second, predictor variables existing prediction model(s) published coefficient (e.g. log-odds-ratio log-hazard-ratio), given values model_info. entering information multiple existing prediction models, model_info contain multiple rows (one per existing model). , given model contain predictor variable included another model, set NA; see examples . case model_type = \"logistic\", model_info must contain column named \"Intercept\", gives intercept coefficient existing logistic regression models (taken exactly previously published); first column model_info. model_type = \"survival\", baseline cumulative hazard model(s) can specified cum_hazard. baseline cumulative hazard existing survival model available, leave NULL; limit validation metrics can calculated. Note, column names model_info match columns new data existing model(s) applied (.e. new data provided functions within package corresponding predictor variables entered model_info). See pred_predict, pred_validate, pred_update pred_stacked_regression information.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_input_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Input information about an existing prediction model — pred_input_info","text":"","code":"#Example 1 - logistic regression existing model # create a data.frame of the model coefficients, with columns being variables coefs_table <- data.frame(\"Intercept\" = -3.4,                           \"SexM\" = 0.306,                           \"Smoking_Status\" = 0.628,                           \"Diabetes\" = 0.499,                           \"CKD\" = 0.538) #pass this into pred_input_info() Existing_Logistic_Model <- pred_input_info(model_type = \"logistic\",                                            model_info = coefs_table) summary(Existing_Logistic_Model) #> Information about 1 existing model(s) of type 'logistic'  #>  #> Model Coefficients  #> =================================  #>   Intercept  SexM Smoking_Status Diabetes   CKD #> 1      -3.4 0.306          0.628    0.499 0.538 #>  #> Model Functional Form  #> =================================  #> SexM + Smoking_Status + Diabetes + CKD  #Example 2 - survival model example; uses an example dataset within the #             package. pred_input_info(model_type = \"survival\",                 model_info = SYNPM$Existing_TTE_models[2,],                 cum_hazard = SYNPM$TTE_mod2_baseline) #>  #>  Formula:  #> ~Age + SexM + Smoking_Status + Diabetes + Creatinine #> <environment: 0x56359ed03ed0> #>  #>  Coefficients:  #>          Age      SexM Smoking_Status  Diabetes Creatinine #> 2 0.02089659 0.2038455      0.5118238 0.1457449  0.3938243  #Example 3 - Input information about multiple models summary(pred_input_info(model_type = \"logistic\",                         model_info = SYNPM$Existing_logistic_models)) #> Information about 3 existing model(s) of type 'logistic'  #>  #> Model Coefficients  #> =================================  #> [[1]] #>   Intercept        Age      SexM Smoking_Status  Diabetes Creatinine #> 1 -3.995452 0.01150886 0.2673809      0.7511888 0.5230999  0.5781238 #>  #> [[2]] #>   Intercept      SexM Smoking_Status  Diabetes Creatinine #> 2 -2.281796 0.2227019      0.5281743 0.2002136  0.4337511 #>  #> [[3]] #>   Intercept Smoking_Status   Diabetes Creatinine #> 3 -3.012865      0.5645417 -0.1223695  0.7314432 #>  #>  #> Model Functional Form  #> =================================  #> Model 1: Age + SexM + Smoking_Status + Diabetes + Creatinine #> Model 2: SexM + Smoking_Status + Diabetes + Creatinine #> Model 3: Smoking_Status + Diabetes + Creatinine"},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Make predictions from an existing prediction model — pred_predict","title":"Make predictions from an existing prediction model — pred_predict","text":"Use existing prediction model estimate predicted risks outcome observation new dataset.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make predictions from an existing prediction model — pred_predict","text":"","code":"pred_predict(   x,   new_data,   binary_outcome = NULL,   survival_time = NULL,   event_indicator = NULL,   time_horizon = NULL )"},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make predictions from an existing prediction model — pred_predict","text":"x object class \"predinfo\" produced calling pred_input_info. new_data data.frame upon predictions obtained using prediction model. binary_outcome Character variable giving name column new_data represents observed binary outcomes (coded 0 1 non-event event, respectively). relevant model_type=\"logistic\"; leave NULL otherwise. Leave NULL new_data contain outcomes. survival_time Character variable giving name column new_data represents observed survival times. relevant model_type=\"survival\"; leave NULL otherwise. Leave NULL new_data contain survival outcomes. event_indicator Character variable giving name column new_data represents observed survival indicator (1 event, 0 censoring). relevant model_type=\"survival\"; leave NULL otherwise. Leave NULL new_data contain survival outcomes. time_horizon survival models, integer giving time horizon (post baseline) prediction required (.e. t P(T<t) estimated). Currently, must match time x$cum_hazard. left NULL, predicted risks returned, just linear predictor.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make predictions from an existing prediction model — pred_predict","text":"pred_predict returns list containing following components: LinearPredictor = linear predictor observation new data (.e., linear combination models predictor variables corresponding coefficients) PredictedRisk = predicted risk observation new data TimeHorizon = survival models, integer giving time horizon prediction made Outcomes = vector outcomes/endpoints (available).","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_predict.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make predictions from an existing prediction model — pred_predict","text":"function takes relevant information existing prediction model (supplied calling pred_input_info), returns linear predictor predicted risks individual/observation new_data. existing prediction model based logistic regression (.e., x$model_type == \"logistic\"), predicted risks predicted probability binary outcome conditional predictor variables new data (.e., P(Y=1 | X)). existing prediction model based time--event/survival model (.e., x$model_type == \"survival\"), predicted risks can calculated baseline cumulative hazard provided; case, predicted risks one minus survival probability (.e., 1 - S(T>time horizon | X)). new_data data.frame, row observation (e.g. patient) variable/column predictor variable. predictor variables need include (minimum) predictor variables included existing prediction model (.e., variable names supplied pred_input_info, model_info parameter, must match name variables new_data). factor variables within new_data must converted dummy (0/1) variables calling function. dummy_vars can help . See examples. binary_outcome, survival_time event_indicator used specify outcome variable(s) within new_data (use binary_outcome x$model_type = \"logistic\", use survival_time event_indicator x$model_type = \"survival\").","code":""},{"path":[]},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_predict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make predictions from an existing prediction model — pred_predict","text":"","code":"#Example 1 - logistic regression existing model - shows handling of factor variables coefs_table <- data.frame(\"Intercept\" = -3.4,                           \"Sex_M\" = 0.306,                           \"Smoking_Status\" = 0.628) existing_Logistic_Model <- pred_input_info(model_type = \"logistic\",                                            model_info = coefs_table) new_df <- data.frame(\"Sex\" = as.factor(c(\"M\", \"F\", \"M\", \"M\", \"F\", \"F\", \"M\")),                      \"Smoking_Status\" = c(1, 0, 0, 1, 1, 0, 1)) #new_df has a factor variable, so needs indicator variables creating before pred_predict: new_df_indicators <- dummy_vars(new_df) pred_predict(x = existing_Logistic_Model,              new_data = new_df_indicators) #> $LinearPredictor #> [1] -2.466 -3.400 -3.094 -2.466 -2.772 -3.400 -2.466 #>  #> $PredictedRisk #> [1] 0.07827635 0.03229546 0.04335543 0.07827635 0.05885613 0.03229546 0.07827635 #>  #> $Outcomes #> NULL #>   #Example 2 - survival model example; uses an example dataset within the #             package. Multiple existing models model2 <- pred_input_info(model_type = \"survival\",                           model_info = SYNPM$Existing_TTE_models,                           cum_hazard = list(SYNPM$TTE_mod1_baseline,                                                 SYNPM$TTE_mod2_baseline,                                                 SYNPM$TTE_mod3_baseline)) pred_predict(x = model2,              new_data = SYNPM$ValidationData[1:10,],              survival_time = \"ETime\",              event_indicator = \"Status\",              time_horizon = 5) #> [[1]] #> [[1]]$LinearPredictor #>  [1] 0.8512214 1.2003842 0.7529033 1.7412421 1.4264254 0.8998310 0.9082076 #>  [8] 1.3527208 1.1508770 0.5215825 #>  #> [[1]]$PredictedRisk #>  [1] 0.2466734 0.3307674 0.2264248 0.4983138 0.3955802 0.2572276 0.2590832 #>  [8] 0.3735659 0.3176582 0.1843038 #>  #> [[1]]$TimeHorizon #> [1] 5 #>  #> [[1]]$Outcomes #>  [1] 5.00000000+ 0.02824273  5.00000000+ 2.77747285  5.00000000+ 5.00000000+ #>  [7] 2.99792812  3.19669111  2.78071011  0.29270868  #>  #>  #> [[2]] #> [[2]]$LinearPredictor #>  [1] 1.412099 1.693712 1.336624 1.907005 1.859033 1.363840 1.470386 1.596060 #>  [9] 1.710236 1.178556 #>  #> [[2]]$PredictedRisk #>  [1] 0.5637400 0.6669059 0.5366225 0.7435170 0.7266379 0.5463529 0.5849280 #>  [8] 0.6310348 0.6729511 0.4814651 #>  #> [[2]]$TimeHorizon #> [1] 5 #>  #> [[2]]$Outcomes #>  [1] 5.00000000+ 0.02824273  5.00000000+ 2.77747285  5.00000000+ 5.00000000+ #>  [7] 2.99792812  3.19669111  2.78071011  0.29270868  #>  #>  #> [[3]] #> [[3]]$LinearPredictor #>  [1] 0.8162710 1.1756009 0.8363372 1.2931219 1.4067912 0.8589199 0.8759559 #>  [8] 1.4347014 1.2503379 0.6006843 #>  #> [[3]]$PredictedRisk #>  [1] 0.3090821 0.4111573 0.3142406 0.4487901 0.4869303 0.3201236 0.3246159 #>  [8] 0.4965302 0.4348664 0.2577218 #>  #> [[3]]$TimeHorizon #> [1] 5 #>  #> [[3]]$Outcomes #>  [1] 5.00000000+ 0.02824273  5.00000000+ 2.77747285  5.00000000+ 5.00000000+ #>  [7] 2.99792812  3.19669111  2.78071011  0.29270868  #>  #>"},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_stacked_regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform Stacked Regression on Existing Prediction Models — pred_stacked_regression","title":"Perform Stacked Regression on Existing Prediction Models — pred_stacked_regression","text":"function takes set existing prediction models, uses new dataset combine/aggregate single 'meta-model', described Debray et al. 2014.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_stacked_regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform Stacked Regression on Existing Prediction Models — pred_stacked_regression","text":"","code":"pred_stacked_regression(   x,   positivity_constraint = FALSE,   new_data,   binary_outcome = NULL,   survival_time = NULL,   event_indicator = NULL )"},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_stacked_regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform Stacked Regression on Existing Prediction Models — pred_stacked_regression","text":"x object class \"predinfo\" produced calling pred_input_info containing information least two existing prediction models. positivity_constraint TRUE/FALSE denoting weights within stacked regression model constrained non-negative (TRUE) allowed take value (FALSE). See details. new_data data.frame upon prediction models aggregated. binary_outcome Character variable giving name column new_data represents observed binary outcomes (coded 0 1 non-event event, respectively). relevant model_type=\"logistic\"; leave NULL otherwise. Leave NULL new_data contain outcomes. survival_time Character variable giving name column new_data represents observed survival times. relevant x$model_type=\"survival\"; leave NULL otherwise. event_indicator Character variable giving name column new_data represents observed survival indicator (1 event, 0 censoring). relevant x$model_type=\"survival\"; leave NULL otherwise.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_stacked_regression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform Stacked Regression on Existing Prediction Models — pred_stacked_regression","text":"object class \"predSR\". detailed pred_input_info, added element containing estimates meta-model obtained stacked regression.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_stacked_regression.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform Stacked Regression on Existing Prediction Models — pred_stacked_regression","text":"function takes set (previously estimated) prediction models originally developed prediction task, pool/aggregate single prediction model (meta-model) using stacked regression based new data (data used develop existing models). methodological details can found Debray et al. 2014. Given existing models likely highly co-linear (since developed prediction task), suggested impose positivity constraint weights stacked regression model (Debray et al. 2014.). positivity_constraint set TRUE, stacked regression model estimated optimising (log-)likelihood using bound constrained optimization (\"L-BFGS-B\"). currently implemented logistic regression models (.e., x$model_type=\"logistic\"). survival models, positivity_constraint = FALSE. new_data data.frame, row observation (e.g. patient) variable/column predictor variable. predictor variables need include (minimum) predictor variables included existing prediction models (.e., variable names supplied pred_input_info, model_info parameter, must match name variables new_data). factor variables within new_data must converted dummy (0/1) variables calling function. dummy_vars can help . See pred_predict examples. binary_outcome, survival_time event_indicator used specify outcome variable(s) within new_data (use binary_outcome x$model_type = \"logistic\", use survival_time event_indicator x$model_type = \"survival\").","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_stacked_regression.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Perform Stacked Regression on Existing Prediction Models — pred_stacked_regression","text":"Debray, T.P., Koffijberg, H., Nieboer, D., Vergouwe, Y., Steyerberg, E.W. Moons, K.G. (2014), Meta-analysis aggregation multiple published prediction models. Statistics Medicine, 33: 2341-2362","code":""},{"path":[]},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_stacked_regression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform Stacked Regression on Existing Prediction Models — pred_stacked_regression","text":"","code":"LogisticModels <- pred_input_info(model_type = \"logistic\",                                   model_info = SYNPM$Existing_logistic_models) SR <- pred_stacked_regression(x = LogisticModels,                               new_data = SYNPM$ValidationData,                               binary_outcome = \"Y\") summary(SR) #> Existing models aggregated using stacked regression #> The model stacked regression weights are as follows:  #> (Intercept)         LP1         LP2         LP3  #>  0.02781941  0.46448799  0.15626108  0.16282116  #>  #> Updated Model Coefficients  #> =================================  #>   Intercept         Age      SexM Smoking_Status  Diabetes Creatinine #> 1 -2.675134 0.005345728 0.1589948      0.5233706 0.2543348  0.4554044 #>  #> Model Functional Form  #> =================================  #> Age + SexM + Smoking_Status + Diabetes + Creatinine  #Survival model example: TTModels <- pred_input_info(model_type = \"survival\",                             model_info = SYNPM$Existing_TTE_models,                             cum_hazard = list(SYNPM$TTE_mod1_baseline,                                                   SYNPM$TTE_mod2_baseline,                                                   SYNPM$TTE_mod3_baseline)) SR <- pred_stacked_regression(x = TTModels,                               new_data = SYNPM$ValidationData,                               survival_time = \"ETime\",                               event_indicator = \"Status\") summary(SR) #> Existing models aggregated using stacked regression #> The model stacked regression weights are as follows:  #>        LP1        LP2        LP3  #> -0.2707658  1.8832932 -0.4488339  #>  #> The new model baseline cumulative hazard is:  #>           time       hazard #> 1 2.021278e-06 5.338425e-06 #> 2 1.630775e-05 1.067721e-05 #> 3 3.600450e-05 1.601631e-05 #> 4 4.006704e-05 2.135604e-05 #> 5 6.484743e-05 2.669604e-05 #> 6 1.216613e-04 3.203626e-05 #> ... #>  #> Updated Model Coefficients  #> =================================  #>          Age      SexM Smoking_Status  Diabetes Creatinine #> 1 0.03363821 0.2725367      0.5354202 0.1595384  0.3142822 #>  #> Model Functional Form  #> =================================  #> Age + SexM + Smoking_Status + Diabetes + Creatinine"},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_update.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform Model Updating on an Existing Prediction Model — pred_update","title":"Perform Model Updating on an Existing Prediction Model — pred_update","text":"function takes existing (previously developed) prediction model applies various model updating methods tailor/adapt new dataset. Various levels updating possible, ranging model re-calibration model refit.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_update.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform Model Updating on an Existing Prediction Model — pred_update","text":"","code":"pred_update(   x,   update_type = c(\"intercept_update\", \"recalibration\", \"refit\"),   new_data,   binary_outcome = NULL,   survival_time = NULL,   event_indicator = NULL )"},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform Model Updating on an Existing Prediction Model — pred_update","text":"x object class \"predinfo\" produced calling pred_input_info containing information exactly one existing prediction model. update_type character variable specifying level updating required. new_data data.frame upon prediction models updated. binary_outcome Character variable giving name column new_data represents observed binary outcomes (coded 0 1 non-event event, respectively). relevant model_type=\"logistic\"; leave NULL otherwise. Leave NULL new_data contain outcomes. survival_time Character variable giving name column new_data represents observed survival times. relevant x$model_type=\"survival\"; leave NULL otherwise. event_indicator Character variable giving name column new_data represents observed survival indicator (1 event, 0 censoring). relevant x$model_type=\"survival\"; leave NULL otherwise.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_update.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform Model Updating on an Existing Prediction Model — pred_update","text":"object class \"predUpdate\". detailed pred_input_info, added element containing estimates model updating update type.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_update.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform Model Updating on an Existing Prediction Model — pred_update","text":"function takes single existing (previously estimated) prediction model, apply various model discrete model updating methods (see Su et al. 2018) tailor model new dataset. type updating method selected update_type parameter, options: \"intercept_update\", \"recalibration\" \"refit\". \"intercept_update\" corrects overall calibration---large model, altering model intercept (baseline hazard) suit new dataset. achieved fitting logistic model (existing model type logistic) time--event model (existing model type survival) new dataset, linear predictor covariate, coefficient fixed unity (.e. offset). \"recalibration\" corrects calibration---large /-fitting, fitting logistic model (existing model type logistic) time--event model (existing model type survival) new dataset, linear predictor covariate. Finally, \"refit\" takes original model structure re-estimates coefficients; effect re-developing original model new data. new_data data.frame, row observation (e.g. patient) variable/column predictor variable. predictor variables need include (minimum) predictor variables included existing prediction model (.e., variable names supplied pred_input_info, model_info parameter, must match name variables new_data). factor variables within new_data must converted dummy (0/1) variables calling function. dummy_vars can help . See pred_predict examples. binary_outcome, survival_time event_indicator used specify outcome variable(s) within new_data (use binary_outcome x$model_type = \"logistic\", use survival_time event_indicator x$model_type = \"survival\").","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_update.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Perform Model Updating on an Existing Prediction Model — pred_update","text":"Su TL, Jaki T, Hickey GL, Buchan , Sperrin M. review statistical updating methods clinical prediction models. Stat Methods Med Res. 2018 Jan;27(1):185-197. doi: 10.1177/0962280215626466.","code":""},{"path":[]},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_update.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform Model Updating on an Existing Prediction Model — pred_update","text":"","code":"#Example 1 - update time-to-event model by updating the baseline hazard in new dataset model1 <- pred_input_info(model_type = \"survival\",                           model_info = SYNPM$Existing_TTE_models[1,],                           cum_hazard = SYNPM$TTE_mod1_baseline) recalibrated_model1 <- pred_update(x = model1,                                    update_type = \"intercept_update\",                                    new_data = SYNPM$ValidationData,                                    survival_time = \"ETime\",                                    event_indicator = \"Status\") summary(recalibrated_model1) #> Original model was updated with type intercept_update #> The new model baseline cumulative hazard is:  #>           time       hazard #> 1 2.021278e-06 1.498399e-05 #> 2 1.630775e-05 2.996905e-05 #> 3 3.600450e-05 4.495490e-05 #> 4 4.006704e-05 5.994284e-05 #> 5 6.484743e-05 7.493149e-05 #> 6 1.216613e-04 8.992081e-05 #> ... #>  #> Updated Model Coefficients  #> =================================  #>           Age      SexM Smoking_Status  Diabetes Creatinine #> 1 0.007014587 0.2249174      0.6852695 0.4245074   0.587486 #>  #> Model Functional Form  #> =================================  #> Age + SexM + Smoking_Status + Diabetes + Creatinine"},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_val_probs.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Predicted Probabilities — pred_val_probs","title":"Validate Predicted Probabilities — pred_val_probs","text":"function included situations one vector predicted probabilities model vector observed binary outcomes wish validate predictions . See pred_validate main validation function package.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_val_probs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Predicted Probabilities — pred_val_probs","text":"","code":"pred_val_probs(binary_outcome, Prob, cal_plot = TRUE, level = 0.95, ...)"},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_val_probs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Predicted Probabilities — pred_val_probs","text":"binary_outcome vector binary outcomes (coded 1 outcome happened, 0 otherwise). Must length Prob Prob vector predicted probabilities. Must length binary_outcome. cal_plot indicate flexible calibration plot produced (TRUE) (FALSE). level confidence level required performance metrics. Defaults 95%. Must value 0 1. ... plotting arguments calibration plot. See Details .","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_val_probs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Predicted Probabilities — pred_val_probs","text":"object class \"predvalidate\", list containing relevant calibration discrimination measures. See pred_validate details.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_val_probs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate Predicted Probabilities — pred_val_probs","text":"function takes vector observed binary outcomes, corresponding vector predicted risks (e.g. logistic regression CPM), calculates measures predictive performance. function intended standalone way validating predicted risks binary outcomes outside usual pred_input_info() -> pred_validate() package workflow. See pred_validate main validation function package. Various metrics calibration (agreement observed risk predicted risks, across full risk range) discrimination (ability model distinguish develop outcome ) calculated. calibration, observed--expected ratio, calibration intercept calibration slopes estimated. calibration intercept estimated fitting logistic regression model observed binary outcomes, linear predictor model offset. calibration slope, logistic regression model fit observed binary outcome linear predictor model covariate. discrimination, function estimates area receiver operating characteristic curve (AUC). Various metrics also calculated assess overall accuracy (Brier score, Cox-Snell R2). flexible calibration plot produced. Specify parameter cal_plot indicate whether calibration plot produced (TRUE), (FALSE). See pred_validate details plot, details optional plotting arguments.","code":""},{"path":[]},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_val_probs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate Predicted Probabilities — pred_val_probs","text":"","code":"# simulate some data for purposes of example illustration set.seed(1234) x1 <- rnorm(2000) LP <- -2 + (0.5*x1) PR <- 1/(1+exp(-LP)) y <- rbinom(2000, 1, PR)  #fit hypothetical model to the simulated data mod <- glm(y[1:1000] ~ x1[1:1000], family = binomial(link=\"logit\"))  #obtain the predicted risks from the model pred_risk <- predict(mod, type = \"response\",                       newdata = data.frame(\"x1\" = x1[1001:2000]))  #Use pred_val_probs to validate the predicted risks against the #observed outcomes summary(pred_val_probs(binary_outcome = y[1001:2000],                         Prob = pred_risk,                         cal_plot = FALSE)) #> Calibration Measures  #> ---------------------------------  #>                         Estimate Lower 95% Confidence Interval #> Observed:Expected Ratio   0.8018                        0.6740 #> Calibration Intercept    -0.2585                       -0.4563 #> Calibration Slope         1.2460                        0.7817 #>                         Upper 95% Confidence Interval #> Observed:Expected Ratio                        0.9539 #> Calibration Intercept                         -0.0608 #> Calibration Slope                              1.7102 #>  #>  Also examine the calibration plot, if produced.  #>  #> Discrimination Measures  #> ---------------------------------  #>     Estimate Lower 95% Confidence Interval Upper 95% Confidence Interval #> AUC   0.6523                        0.5998                        0.7048 #>  #>  #> Overall Performance Measures  #> ---------------------------------  #> Cox-Snell R-squared: 0.0211 #> Nagelkerke R-squared: 0.0416 #> Brier Score (CI): 0.098 (0.0832, 0.1128) #>  #>  Also examine the distribution plot of predicted risks."},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_validate.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate an existing prediction — pred_validate","title":"Validate an existing prediction — pred_validate","text":"Validate existing prediction model, calculate predictive performance new (validation) dataset.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_validate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate an existing prediction — pred_validate","text":"","code":"pred_validate(   x,   new_data,   binary_outcome = NULL,   survival_time = NULL,   event_indicator = NULL,   time_horizon = NULL,   level = 0.95,   cal_plot = TRUE,   ... )"},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_validate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate an existing prediction — pred_validate","text":"x object class \"predinfo\" produced calling pred_input_info. new_data data.frame upon prediction model evaluated. binary_outcome Character variable giving name column new_data represents observed binary outcomes (coded 0 1 non-event event, respectively). relevant model_type=\"logistic\"; leave NULL otherwise. Leave NULL new_data contain outcomes. survival_time Character variable giving name column new_data represents observed survival times. relevant x$model_type=\"survival\"; leave NULL otherwise. event_indicator Character variable giving name column new_data represents observed survival indicator (1 event, 0 censoring). relevant x$model_type=\"survival\"; leave NULL otherwise. time_horizon survival models, integer giving time horizon (post baseline) prediction required. Currently, must match time x$cum_hazard. level confidence level required performance metrics. Defaults 95%. Must value 0 1. cal_plot indicate flexible calibration plot produced (TRUE) (FALSE). ... plotting arguments calibration plot. See Details .","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_validate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate an existing prediction — pred_validate","text":"pred_validate returns object class \"predvalidate\", child classes per model_type. list performance metrics, estimated applying existing prediction model new_data. object class \"predvalidate\" list containing relevant calibration discrimination measures. logistic regression models, include observed:expected ratio, calibration-intercept, calibration slope, area ROC curve, R-squared, Brier Score. survival models, include observed:expected ratio (cum_hazard provided x), calibration slope, Harrell's C-statistic. Optionally, flexible calibration plot also produced, along box-plot violin plot predicted risk distribution. summary function can used extract print summary performance results (calibration discrimination metrics). graphical assessments performance can extracted using plot.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_validate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate an existing prediction — pred_validate","text":"function takes existing prediction model formatted according pred_input_info, calculates measures predictive performance new data (e.g., within external validation study). information existing prediction model first inputted calling pred_input_info, passing resulting object pred_validate. new_data data.frame, row observation (e.g. patient) variable/column predictor variable. predictor variables need include (minimum) predictor variables included existing prediction model (.e., variable names supplied pred_input_info, model_info parameter, must match name variables new_data). factor variables within new_data must converted dummy (0/1) variables calling function. dummy_vars can help . See pred_predict examples. binary_outcome, survival_time event_indicator used specify outcome variable(s) within new_data (use binary_outcome x$model_type = \"logistic\", use survival_time event_indicator x$model_type = \"survival\"). case validating logistic regression model, function assesses predictive performance predicted risks observed binary outcome. Various metrics calibration (agreement observed risk predicted risks, across full risk range) discrimination (ability model distinguish develop outcome ) calculated. calibration, observed--expected ratio, calibration intercept calibration slopes estimated. calibration intercept estimated fitting logistic regression model observed binary outcomes, linear predictor model offset. calibration slope, logistic regression model fit observed binary outcome linear predictor model covariate. discrimination, function estimates area receiver operating characteristic curve (AUC). Various metrics also calculated assess overall accuracy (Brier score, Cox-Snell R2). case validating survival prediction model, function assesses predictive performance linear predictor (optionally) predicted event probabilities fixed time horizon observed time--event outcome. Various metrics calibration discrimination calculated. calibration, observed--expected ratio specified time_horizon (predicted risks available specification x$cum_hazard) calibration slope produced. discrimination, Harrell's C-statistic calculated. model types, flexible calibration plot produced (survival models, cumulative baseline hazard must available predinfo object, x$cum_hazard). Specify parameter cal_plot indicate whether calibration plot produced (TRUE), (FALSE). calibration plot produced regressing observed outcomes cubic spline logit predicted risks (logistic model) complementary log-log predicted risks (survival model). Users can specify following additional parameters pred_validate modify calibration plot: xlim numeric vector length 2, giving lower upper range x-axis scale - defaults 0 1. Changes match changes ylim plot remains 'square'. ylim numeric vector length 2, giving lower upper range y-axis scale - defaults 0 1. Changes match changes xlim plot remains 'square'. xlab string giving x-axis label. Defaults \"Predicted Probability\". ylab string giving x-axis label. Defaults \"Observed Probability\". pred_rug TRUE/FALSE whether 'rug' placed along x-axis calibration plot showing distribution predicted risks. Defaults FALSE favour examining box-plot/violin plot produced. cal_plot_n_sample numeric value (less nrow(new_data)) giving random subset observations render calibration plot . calibration plot always created using data, rendering speed large datasets, can sometimes useful render plot smaller (random) subset observations. Final (e.g. publication-ready) plots always show full plot, warning created users enter value cal_plot_n_sample.","code":""},{"path":[]},{"path":"https://glenmartin31.github.io/predRupdate/reference/pred_validate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate an existing prediction — pred_validate","text":"","code":"#Example 1 - multiple existing model, with outcome specified; uses #            an example dataset within the package model1 <- pred_input_info(model_type = \"logistic\",                           model_info = SYNPM$Existing_logistic_models) val_results <- pred_validate(x = model1,                              new_data = SYNPM$ValidationData,                              binary_outcome = \"Y\",                              cal_plot = FALSE) summary(val_results) #>  #> Performance Results for Model 1  #> =================================  #> Calibration Measures  #> ---------------------------------  #>                         Estimate Lower 95% Confidence Interval #> Observed:Expected Ratio   1.9006                        1.8368 #> Calibration Intercept     0.7323                        0.6921 #> Calibration Slope         0.6484                        0.5576 #>                         Upper 95% Confidence Interval #> Observed:Expected Ratio                        1.9666 #> Calibration Intercept                          0.7726 #> Calibration Slope                              0.7392 #>  #>  Also examine the calibration plot, if produced.  #>  #> Discrimination Measures  #> ---------------------------------  #>     Estimate Lower 95% Confidence Interval Upper 95% Confidence Interval #> AUC   0.5814                        0.5702                        0.5927 #>  #>  #> Overall Performance Measures  #> ---------------------------------  #> Cox-Snell R-squared: -0.0481 #> Nagelkerke R-squared: -0.0863 #> Brier Score (CI): 0.1249 (0.1219, 0.1279) #>  #>  Also examine the distribution plot of predicted risks.  #>  #> Performance Results for Model 2  #> =================================  #> Calibration Measures  #> ---------------------------------  #>                         Estimate Lower 95% Confidence Interval #> Observed:Expected Ratio   0.8945                        0.8645 #> Calibration Intercept    -0.1325                       -0.1725 #> Calibration Slope         0.9868                        0.8489 #>                         Upper 95% Confidence Interval #> Observed:Expected Ratio                        0.9256 #> Calibration Intercept                         -0.0926 #> Calibration Slope                              1.1247 #>  #>  Also examine the calibration plot, if produced.  #>  #> Discrimination Measures  #> ---------------------------------  #>     Estimate Lower 95% Confidence Interval Upper 95% Confidence Interval #> AUC   0.5828                        0.5716                        0.5941 #>  #>  #> Overall Performance Measures  #> ---------------------------------  #> Cox-Snell R-squared: 0.0074 #> Nagelkerke R-squared: 0.0132 #> Brier Score (CI): 0.1206 (0.1172, 0.124) #>  #>  Also examine the distribution plot of predicted risks.  #>  #> Performance Results for Model 3  #> =================================  #> Calibration Measures  #> ---------------------------------  #>                         Estimate Lower 95% Confidence Interval #> Observed:Expected Ratio   1.5945                        1.5410 #> Calibration Intercept     0.5324                        0.4923 #> Calibration Slope         0.7212                        0.5981 #>                         Upper 95% Confidence Interval #> Observed:Expected Ratio                        1.6499 #> Calibration Intercept                          0.5724 #> Calibration Slope                              0.8443 #>  #>  Also examine the calibration plot, if produced.  #>  #> Discrimination Measures  #> ---------------------------------  #>     Estimate Lower 95% Confidence Interval Upper 95% Confidence Interval #> AUC   0.5613                        0.5497                        0.5728 #>  #>  #> Overall Performance Measures  #> ---------------------------------  #> Cox-Snell R-squared: -0.0249 #> Nagelkerke R-squared: -0.0446 #> Brier Score (CI): 0.1234 (0.1202, 0.1266) #>  #>  Also examine the distribution plot of predicted risks."},{"path":[]},{"path":"https://glenmartin31.github.io/predRupdate/news/index.html","id":"predrupdate-021-1","dir":"Changelog","previous_headings":"","what":"predRupdate 0.2.1","title":"predRupdate 0.2.1","text":"Fixes issue internal tests ggplot classes, ggplot2 transitioned S7 (#18)","code":""},{"path":"https://glenmartin31.github.io/predRupdate/news/index.html","id":"predrupdate-020","dir":"Changelog","previous_headings":"","what":"predRupdate 0.2.0","title":"predRupdate 0.2.0","text":"CRAN release: 2024-08-23 Added new function, pred_val_probs(), allows users validate vector binary outcomes corresponding vector predicted risks. Acts standalone way validating predicted risks binary outcomes outside usual pred_input_info() -> pred_validate() workflow logistic models. Added options pred_validate() allow users specify confidence interval width performance metrics. Revised calculation confidence intervals O:E ratio, added calculation confidence intervals Brier score. Added option (argument ‘cal_plot_n_sample’) pred_validate() pred_val_probs() render calibration plot subset data, purposes rendering speed. calibration plot always created using data, rendering speed large datasets, can sometimes useful render plot smaller (random) subset observations. Final (e.g. publication-ready) plots always show full plot, warning created users use option. similar reasons rending speed, rug x-axis calibration plot now shown default. pred_input_info() now contains checks ensure variable names model_info, variable names new_data passed functions ‘clean’ (.e., dont contain spaces, punctuation, brackets, etc.) Added note vignette specification baseline hazard using basehaz() survival package, regarding default scaling centering variables.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/news/index.html","id":"predrupdate-011","dir":"Changelog","previous_headings":"","what":"predRupdate 0.1.1","title":"predRupdate 0.1.1","text":"CRAN release: 2023-12-12 Changed naming calibration metrics summary.predvalidate rename “calibration---large”” logistic models “calibration intercept”. predvalidate() now calculates observed:expected ratio validating logistic models, along calibration intercept pred_validate() now stores calibration plots (ggplot) part output (previous versions package just printed plot without outputting plot object). facilitates users saving changing style plot. Added vignette show validate existing CPM includes spline term","code":""},{"path":"https://glenmartin31.github.io/predRupdate/news/index.html","id":"predrupdate-010","dir":"Changelog","previous_headings":"","what":"predRupdate 0.1.0","title":"predRupdate 0.1.0","text":"CRAN release: 2023-04-27 Initial release predRupdate.","code":""},{"path":"https://glenmartin31.github.io/predRupdate/news/index.html","id":"predrupdate-0009000","dir":"Changelog","previous_headings":"","what":"predRupdate 0.0.0.9000","title":"predRupdate 0.0.0.9000","text":"Added NEWS.md file track changes package.","code":""}]
